{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow and Deep Learning\n",
    "\n",
    "In this lab assignment, first you will learn how to build and train a neural network that recognises handwritten digits, and then you will build LeNet-5 CNN architecture, which is widely used for handwritten digit recognition. At the end of this lab assignment, you will make AlexNet CNN architecture, which won the 2012 ImageNet ILSVRC challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Dataset\n",
    "In the first part of the assignment, we use the MNIST dataset, which is a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. There are 70,000 images, and each image has 784 features. This is because each image is 28×28=784 pixels, and each feature simply represents one pixel's intensity, from 0 (white) to 255 (black). The following figure shows a few images from the MNIST dataset to give you a feel for the complexity of the classification task.\n",
    "\n",
    "<img src=\"figs/1-mnist.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "To begin the assignment, first, use `mnist_data.read_data_sets` and download images and labels. It return two lists, called `mnist.test` with 10K images+labels, and `mnist.train` with 60K images+labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-37cf921d2cab>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/alexbacce/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/alexbacce/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/alexbacce/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/alexbacce/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/alexbacce/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data\n",
    "\n",
    "mnist = mnist_data.read_data_sets(\"MNIST_data/\", one_hot = True, reshape=False, validation_size=0)\n",
    "\n",
    "# (x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. A One-Layer Neural Network\n",
    "<img src=\"figs/2-comic1.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "Let's start by building a one-layer neural network. Handwritten digits in the MNIST dataset are 28x28 pixel greyscale images. The simplest approach for classifying them is to use the 28x28=784 pixels as inputs for a **one-layer neural network**. Each neuron in the network does a weighted sum of all of its inputs, adds a bias and then feeds the result through some non-linear activation function. Here we design a one-layer neural network with 10 output neurons since we want to classify digits into 10 classes (0 to 9).\n",
    "<img src=\"figs/3-one_layer.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "For a classification problem, an *activation function* that works well is **softmax**. Applying softmax on a vector is done by taking the exponential of each element and then normalising the vector.\n",
    "<img src=\"figs/4-softmax.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "We can summarise the behaviour of this single layer of neurons into a simple formula using a *matrix multiply*. If we give input data into the network in *mini-batch* of 100 images, it produces 100 predictions as the output. We define the **weights matrix $W$** with 10 columns, in which each column indicates the weight of a one class (a single digit), from 0 to 9. Using the first column of $W$, we can compute the weighted sum of all the pixels of the first image. This sum corresponds to the first neuron that points to the number 0. Using the second column of $W$, we do the same for the second neuron (number 1) and so on until the 10th neuron. We can then repeat the operation for the remaining 99 images in the mini-batch. If we call $X$ the matrix containing our 100 images (each row corresponds to one digit), all the weighted sums for our 10 neurons, computed on 100 images are simply $X.W$. Each neuron must now add its bias. Since we have 10 neurons, we have 10 bias constants. We finally apply the **softmax activation function** and obtain the formula describing a one-layer neural network, applied to 100 images.\n",
    "<img src=\"figs/5-xw.png\" style=\"width: 600px;\"/>\n",
    "<img src=\"figs/6-softmax2.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "Then, we need to use the **cross-entropy** to measure how good the predictions are, i.e., the distance between what the network tells us and what we know to be the truth. The cross-entropy is a function of weights, biases, pixels of the training image and its known label. If we compute the partial derivatives of the cross-entropy relatively to all the weights and all the biases, we obtain a **gradient**, computed for a given image, label and present value of weights and biases. We can update weights and biases by a fraction of the gradient and do the same thing again using the next batch of training images.\n",
    "<img src=\"figs/7-cross_entropy.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Define Variables and Placeholders\n",
    "First we define TensorFlow **variables** and **placeholders**. *Variables* are all the parameters that you want the training algorithm to determine for you (e.g., weights and biases). *Placeholders* are parameters that will be filled with actual data during training (e.g., training images). The shape of the tensor holding the training images is [None, 28, 28, 1] which stands for:\n",
    "  - 28, 28, 1: our images are 28x28 (784) pixels x 1 value per pixel (grayscale). The last number would be 3 for color images and is not really necessary here.\n",
    "  - None: this dimension will be the number of images in the mini-batch. It will be known at training time.\n",
    "\n",
    "We also need an additional placeholder for the training labels that will be provided alongside training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "batch_size = 100\n",
    "# neural network with 1 layer of 10 softmax neurons\n",
    "#\n",
    "# · · · · · · · · · ·       (input data, flattened pixels)       X [batch, 784] \n",
    "# \\x/x\\x/x\\x/x\\x/x\\x/    -- fully connected layer (softmax)      W [784, 10]     b[10]\n",
    "#   · · · · · · · ·                                              Y_hat [batch, 10]\n",
    "\n",
    "# input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch\n",
    "X = tf.placeholder(tf.float32, shape = (None, 784))\n",
    "\n",
    "# correct answers will go here\n",
    "Y = tf.placeholder(tf.float32, shape = (None, 10))\n",
    "\n",
    "# weights W[784, 10], 784 = 28 * 28\n",
    "W = tf.Variable(tf.random_uniform(\n",
    "    [784, 10],\n",
    "    minval=0,\n",
    "    maxval=1,\n",
    "    dtype=tf.float32))\n",
    "\n",
    "# biases b[10]\n",
    "b = tf.Variable(tf.random_uniform(\n",
    "    [10],\n",
    "    minval=0,\n",
    "    maxval=1,\n",
    "    dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build The Model\n",
    "Now, we can make a **model** for a one-layer neural network. The formula is the one we explained before, i.e., $\\hat{Y} = softmax(X . W + b)$. You can use the `tf.nn.softmax` and `tf.matmul` to build the model. Here, we need to use the `tf.reshape` to transform our 28x28 images into single vectors of 784 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# flatten the images into a single line of pixels\n",
    "XX = tf.reshape(X, [60000, 784])\n",
    "\n",
    "# The model\n",
    "Y_hat = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define The Cost Function\n",
    "Now, we have model predictions $\\hat{Y}$ and correct labels $Y$, so for each instance $i$ (image) we can compute the cross-entropy as the **cost function**: $cross\\_entropy = -\\sum(Y_i * log(\\hat{Y}i))$. You can use `reduce_mean` to add all the components in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-d16eef3644be>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# cross_entropy = -1 * (tf.to_float(60000 * tf.reduce_mean(Y)) * tf.math.log(tf.to_float(60000 * tf.reduce_mean(Y_hat))))\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = Y_hat, labels = Y)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traine the Model\n",
    "Now, select the gradient descent optimiser `GradientDescentOptimizer` and ask it to minimise the cross-entropy cost. In this step, TensorFlow computes the partial derivatives of the cost function relatively to all the weights and all the biases (the gradient). The gradient is then used to update the weights and biases. Set the learning rate is $0.005$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.005)\n",
    "train_step = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the Model\n",
    "It is time to run the training loop. All the TensorFlow instructions up to this point have been preparing a computation graph in memory but nothing has been computed yet. The computation requires actual data to be fed into the placeholders. This is supplied in the form of a Python dictionary, where the keys are the names of the placeholders. During the trainig print out the cost every 200 steps. Moreove, after training the model, print out the accurray of the model by testing it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.28437\n",
      "1.84385\n",
      "1.70272\n",
      "1.65363\n",
      "1.64154\n",
      "1.6061\n",
      "1.59273\n",
      "1.57056\n",
      "1.55547\n",
      "1.6015\n",
      "1.59846\n",
      "1.55137\n",
      "1.5963\n",
      "1.57656\n",
      "1.59236\n",
      "1.56271\n",
      "1.57591\n",
      "1.58269\n",
      "1.60141\n",
      "1.52589\n",
      "1.57432\n",
      "1.56226\n",
      "1.5606\n",
      "1.52749\n",
      "1.52336\n",
      "Accuracy: 0.9174000024795532\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 5000\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs): \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        if (epoch % 200 == 0):\n",
    "            print(cost.eval(session = sess, feed_dict = {X: batch_x, Y: batch_y}))\n",
    "        \n",
    "        sess.run(train_step, feed_dict = {X: batch_x, Y: batch_y})\n",
    "        \n",
    "    correct_predictions = tf.equal(tf.argmax(Y_hat, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    \n",
    "    print(\"Accuracy: {}\".format(sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Add More Layers\n",
    "\n",
    "<img src=\"figs/8-comic2.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "Now, let's improve the recognition accuracy by adding more layers to the neural network. The neurons in the second layer, instead of computing weighted sums of pixels will compute weighted sums of neuron outputs from the previous layer. We keep the softmax function as the activation function on the last layer, but on intermediate layers we will use the the **sigmoid** activation function. So, let's build a five-layer fully connected neural network with the following structure, and train the model with the trainging data and print out its accuracy on the test data.\n",
    "<img src=\"figs/9-five_layer.png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.30892\n",
      "2.31485\n",
      "2.31197\n",
      "2.31044\n",
      "2.30698\n",
      "2.31267\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-a998f7a383ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# neural network with five layers\n",
    "#\n",
    "# · · · · · · · · · ·          (input data, flattened pixels)       X [batch, 784]   \n",
    "# \\x/x\\x/x\\x/x\\x/x\\x/       -- fully connected layer (sigmoid)      W1 [784, 200]      B1 [200]\n",
    "#  · · · · · · · · ·                                                Y1_hat [batch, 200]\n",
    "#   \\x/x\\x/x\\x/x\\x/         -- fully connected layer (sigmoid)      W2 [200, 100]      B2 [100]\n",
    "#    · · · · · · ·                                                  Y2_hat [batch, 100]\n",
    "#     \\x/x\\x/x\\x/           -- fully connected layer (sigmoid)      W3 [100, 60]       B3 [60]\n",
    "#      · · · · ·                                                    Y3_hat [batch, 60]\n",
    "#       \\x/x\\x/             -- fully connected layer (sigmoid)      W4 [60, 30]        B4 [30]\n",
    "#        · · ·                                                      Y4_hat [batch, 30]\n",
    "#         \\x/               -- fully connected layer (softmax)      W5 [30, 10]        B5 [10]\n",
    "#          ·                                                        Y_hat [batch, 10]\n",
    "\n",
    "# to reset the Tensorflow default graph\n",
    "reset_graph()\n",
    "\n",
    "########################################\n",
    "# define variables and placeholders\n",
    "########################################\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "Y = tf.placeholder(tf.int64, shape=(None))\n",
    "\n",
    "# five layers and their number of neurons, i.e., 200, 100, 60, 30, and 10\n",
    "W1 = tf.get_variable(\"weights1\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([784, 200]))\n",
    "B1 = tf.get_variable(\"bias1\", dtype=tf.float32, initializer=tf.random_uniform([200]))\n",
    "\n",
    "W2 = tf.get_variable(\"weights2\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([200, 100]))\n",
    "B2 = tf.get_variable(\"bias2\", dtype=tf.float32, initializer=tf.random_uniform([100]))\n",
    "\n",
    "W3 = tf.get_variable(\"weights3\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([100, 60]))\n",
    "B3 = tf.get_variable(\"bias3\", dtype=tf.float32, initializer=tf.random_uniform([60]))\n",
    "\n",
    "W4 = tf.get_variable(\"weights4\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([60, 30]))\n",
    "B4 = tf.get_variable(\"bias4\", dtype=tf.float32, initializer=tf.random_uniform([30]))\n",
    "\n",
    "W5 = tf.get_variable(\"weights5\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([30, 10]))\n",
    "B5 = tf.get_variable(\"bias5\", dtype=tf.float32, initializer=tf.random_uniform([10]))\n",
    "\n",
    "########################################\n",
    "# build the model\n",
    "########################################\n",
    "#XX = tf.reshape([])\n",
    "\n",
    "Y1_hat = tf.nn.sigmoid(tf.matmul(X, W1) + B1)\n",
    "Y2_hat = tf.nn.sigmoid(tf.matmul(Y1_hat, W2) + B2)\n",
    "Y3_hat = tf.nn.sigmoid(tf.matmul(Y2_hat, W3) + B3)\n",
    "Y4_hat = tf.nn.sigmoid(tf.matmul(Y3_hat, W4) + B4)\n",
    "Y_hat = tf.nn.softmax(tf.matmul(Y4_hat, W5) + B5)\n",
    "\n",
    "########################################\n",
    "# define the cost function\n",
    "########################################\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Y_hat, labels = Y))\n",
    "\n",
    "########################################\n",
    "# define the optimizer\n",
    "########################################\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.005)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "########################################\n",
    "# execute the model\n",
    "########################################\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 100\n",
    "n_epochs = 5000\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs): \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        if (epoch % 200 == 0):\n",
    "            print(cross_entropy.eval(session = sess, feed_dict = {X: batch_x, Y: batch_y}))\n",
    "        else: \n",
    "            sess.run(train_step, feed_dict = {X: batch_x, Y: batch_y})\n",
    "        \n",
    "    correct_predictions = tf.equal(tf.argmax(Y_hat, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    \n",
    "    print(\"Accuracy: {}\".format(sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Special Care for Deep Networks\n",
    "As layers were added, neural networks tended to converge with more difficulties. For example, the accuracy could stuck at 0.1. Here, we want to apply some updates to the network we built in the previous part to improve its performance. \n",
    "\n",
    "### ReLU Activation Function\n",
    "<img src=\"figs/10-comic3.png\" style=\"width: 500px;\"/>\n",
    "The sigmoid activation function is actually quite problematic in deep networks. It squashes all values between 0 and 1 and when you do so repeatedly, neuron outputs and their gradients can vanish entirely. An alternative activation function is **ReLU** that shows better performance compare to sigmoid. It looks like as below:\n",
    "<img src=\"figs/11-relu.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "### A Better Optimizer\n",
    "In very high dimensional spaces like here, **saddle points** are frequent. These are points that are not local minima, but where the gradient is nevertheless zero and the gradient descent optimizer stays stuck there. One possible solution to tackle this probelm is to use better optimizers, such as Adam optimizer `tf.train.AdamOptimizer`.\n",
    "\n",
    "### Random Initialisations\n",
    "When working with ReLUs, the best practice is to initialise bias values to small positive values, so that neurons operate in the non-zero range of the ReLU initially.\n",
    "\n",
    "### Learning Rate\n",
    "<img src=\"figs/12-comic4.png\" style=\"width: 500px;\"/>\n",
    "With two, three or four intermediate layers, you can now get close to 98% accuracy, if you push the iterations to 5000 or beyond. But, the results are not very consistent, and the curves jump up and down by a whole percent. A good solution is to start fast and decay the learning rate exponentially from $0.005$ to $0.0001$ for example. In order to pass a different learning rate to the `AdamOptimizer` at each iteration, you will need to define a new placeholder and feed it a new value at each iteration through `feed_dict`. Here is the formula for exponential decay: $learning\\_rate = lr\\_min + (lr\\_max - lr\\_min) * e^{\\frac{-i}{2000}}$, where $i$ is the iteration number.\n",
    "\n",
    "### NaN?\n",
    "In the network you built in the last section, you might see accuracy curve crashes and the console outputs NaN for the cross-entropy. It may happen, because you are attempting to compute a $log(0)$, which is indeed Not A Number (NaN). Remember that the cross-entropy involves a log, computed on the output of the softmax layer. Since softmax is essentially an exponential, which is never zero, we should be fine, but with 32 bit precision floating-point operations, exp(-100) is already a genuine zero. TensorFlow has a handy function that computes the softmax and the cross-entropy in a single step, implemented in a numerically stable way. To use it, you will need to separate the weighted sum plus bias on the last layer, before softmax is applied and then give it with the true values to the function `tf.nn.softmax_cross_entropy_with_logits`.\n",
    "\n",
    "In the code below, apply the following changes and show their impact on the accuracy of the model on training data, as well as the test data:\n",
    "* Replace the sigmoid activation function with ReLU\n",
    "* Use the Adam optimizer\n",
    "* Initialize weights with small random values between -0.2 and +0.2, and make sure biases are initialised with small positive values, for example 0.1\n",
    "* Update the learning rate in different iterations. Start fast and decay the learning rate exponentially from $0.005$ to $0.0001$, i.e., \n",
    "```\n",
    "max_learning_rate = 0.005\n",
    "min_learning_rate = 0.0001\n",
    "decay_speed = 2000.0\n",
    "```\n",
    "* Use `tf.nn.softmax_cross_entropy_with_logits` to prevent getting NaN in output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (100, 28, 28, 1) for Tensor 'Placeholder:0', which has shape '(?, 784)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9534b7715161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             print(cross_entropy.eval(session = sess, feed_dict = {X: batch_x, Y: batch_y, \n\u001b[0;32m--> 104\u001b[0;31m                                                         learning_rate: new_learning_rate}))\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             sess.run(train_step, feed_dict = {X: batch_x, Y: batch_y, \n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5155\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5157\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (100, 28, 28, 1) for Tensor 'Placeholder:0', which has shape '(?, 784)'"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# neural network with 5 layers\n",
    "#\n",
    "# · · · · · · · · · ·          (input data, flattened pixels)       X [batch, 784]   \n",
    "# \\x/x\\x/x\\x/x\\x/x\\x/       -- fully connected layer (sigmoid)      W1 [784, 200]      B1[200]\n",
    "#  · · · · · · · · ·                                                Y1_hat [batch, 200]\n",
    "#   \\x/x\\x/x\\x/x\\x/         -- fully connected layer (sigmoid)      W2 [200, 100]      B2[100]\n",
    "#    · · · · · · ·                                                  Y2_hat [batch, 100]\n",
    "#     \\x/x\\x/x\\x/           -- fully connected layer (sigmoid)      W3 [100, 60]       B3[60]\n",
    "#      · · · · ·                                                    Y3_hat [batch, 60]\n",
    "#       \\x/x\\x/             -- fully connected layer (sigmoid)      W4 [60, 30]        B4[30]\n",
    "#        · · ·                                                      Y4_hat [batch, 30]\n",
    "#         \\x/               -- fully connected layer (softmax)      W5 [30, 10]        B5[10]\n",
    "#          ·                                                        Y_hat [batch, 10]\n",
    "\n",
    "# to reset the Tensorflow default graph\n",
    "reset_graph()\n",
    "\n",
    "########################################\n",
    "# define variables and placeholders\n",
    "########################################\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "Y = tf.placeholder(tf.int64, shape=(None))\n",
    "\n",
    "# variable learning rate\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "# five layers and their number of neurons, i.e., 200, 100, 60, 30, and 10\n",
    "# when using RELUs, make sure biases are initialised with small positive values, for example 0.1\n",
    "W1 = tf.get_variable(\"weights1\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([784, 200], minval=-0.5,\n",
    "    maxval=0.5))\n",
    "B1 = tf.get_variable(\"bias1\", dtype=tf.float32, initializer=tf.random_uniform([200], minval=0,\n",
    "    maxval=1))\n",
    "\n",
    "W2 = tf.get_variable(\"weights2\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([200, 100], minval=-0.5,\n",
    "    maxval=0.5))\n",
    "B2 = tf.get_variable(\"bias2\", dtype=tf.float32, initializer=tf.random_uniform([100], minval=0,\n",
    "    maxval=1))\n",
    "\n",
    "W3 = tf.get_variable(\"weights3\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([100, 60], minval=-0.5,\n",
    "    maxval=0.5))\n",
    "B3 = tf.get_variable(\"bias3\", dtype=tf.float32, initializer=tf.random_uniform([60], minval=0,\n",
    "    maxval=1))\n",
    "\n",
    "W4 = tf.get_variable(\"weights4\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([60, 30], minval=-0.5,\n",
    "    maxval=0.5))\n",
    "B4 = tf.get_variable(\"bias4\", dtype=tf.float32, initializer=tf.random_uniform([30], minval=0,\n",
    "    maxval=1))\n",
    "\n",
    "W5 = tf.get_variable(\"weights5\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([30, 10], minval=-0.5,\n",
    "    maxval=0.5))\n",
    "B5 = tf.get_variable(\"bias5\", dtype=tf.float32, initializer=tf.random_uniform([10], minval=0,\n",
    "    maxval=1))\n",
    "\n",
    "########################################\n",
    "# build the model\n",
    "########################################\n",
    "#XX = <FILL IN>\n",
    "\n",
    "Y1_hat = tf.nn.relu(tf.matmul(X, W1) + B1)\n",
    "Y2_hat = tf.nn.relu(tf.matmul(Y1_hat, W2) + B2)\n",
    "Y3_hat = tf.nn.relu(tf.matmul(Y2_hat, W3) + B3)\n",
    "Y4_hat = tf.nn.relu(tf.matmul(Y3_hat, W4) + B4)\n",
    "Y_hat = tf.nn.relu(tf.matmul(Y4_hat, W5) + B5)\n",
    "\n",
    "########################################\n",
    "# defining the cost function\n",
    "########################################\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = Y_hat, labels = Y)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "########################################\n",
    "# define the optimizer\n",
    "########################################\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "########################################\n",
    "# execute the model\n",
    "########################################\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "max_learning_rate = 0.005\n",
    "min_learning_rate = 0.0001\n",
    "decay_speed = 2000.0\n",
    "\n",
    "batch_size = 100\n",
    "n_epochs = 5000\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs): \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        new_learning_rate = min_learning_rate + tf.math.multiply(tf.math.subtract(max_learning_rate, min_learning_rate), \n",
    "                                tf.math.exp(tf.math.xdivy(tf.math.negative(tf.to_float(epoch)), decay_speed))).eval()\n",
    "\n",
    "        if (epoch % 100 == 0):\n",
    "            print(cross_entropy.eval(session = sess, feed_dict = {X: batch_x, Y: batch_y, \n",
    "                                                        learning_rate: new_learning_rate}))\n",
    "        else: \n",
    "            sess.run(train_step, feed_dict = {X: batch_x, Y: batch_y, \n",
    "                                        learning_rate: new_learning_rate})\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(Y_hat, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    \n",
    "    print(\"Accuracy: {}\".format(sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Overfitting and Dropout\n",
    "<img src=\"figs/13-comic5.png\" style=\"width: 500px;\"/>\n",
    "You will have noticed that cross-entropy curves for test and training data start disconnecting after a couple thousand iterations. The learning algorithm works on training data only and optimises the training cross-entropy accordingly. It never sees test data so it is not surprising that after a while its work no longer has an effect on the test cross-entropy which stops dropping and sometimes even bounces back up. \n",
    "<img src=\"figs/14-overfit.png\" style=\"width: 500px;\"/>\n",
    "This disconnect is usually labeled **overfitting** and when you see it, you can try to apply a regularisation technique called **dropout**. In dropout, at each training iteration, you drop random neurons from the network. You choose a probability `pkeep` for a neuron to be kept, usually between 50% and 75%, and then at each iteration of the training loop, you randomly remove neurons with all their weights and biases. Different neurons will be dropped at each iteration. When testing the performance of your network of course you put all the neurons back (`pkeep = 1`).\n",
    "<img src=\"figs/15-dropout.png\" style=\"width: 500px;\"/>\n",
    "TensorFlow offers a dropout function to be used on the outputs of a layer of neurons. It randomly zeroes-out some of the outputs and boosts the remaining ones by `1 / pkeep`. You can add dropout after each intermediate layer in the network now. \n",
    "\n",
    "In the following code, use the dropout between each layer during the training, and set the probability `pkeep` once to $50%$ and another time to $75%$ and compare their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.gmtime().tm_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2:14) Epoch: 0 Cost: 8373.060546875\n",
      "(2:14) Epoch: 100 Cost: 229.20431518554688\n",
      "(2:14) Epoch: 200 Cost: 234.15896606445312\n",
      "(2:14) Epoch: 300 Cost: 230.45201110839844\n",
      "(2:14) Epoch: 400 Cost: 229.81748962402344\n",
      "(2:15) Epoch: 500 Cost: 231.63775634765625\n",
      "(2:15) Epoch: 600 Cost: 231.17236328125\n",
      "(2:16) Epoch: 700 Cost: 230.04164123535156\n",
      "(2:16) Epoch: 800 Cost: 230.26670837402344\n",
      "(2:17) Epoch: 900 Cost: 229.5806884765625\n",
      "(2:17) Epoch: 1000 Cost: 230.6591796875\n",
      "(2:18) Epoch: 1100 Cost: 229.52447509765625\n",
      "(2:18) Epoch: 1200 Cost: 232.05914306640625\n",
      "(2:19) Epoch: 1300 Cost: 230.8430633544922\n",
      "(2:20) Epoch: 1400 Cost: 230.5386505126953\n",
      "(2:21) Epoch: 1500 Cost: 229.9733123779297\n",
      "(2:21) Epoch: 1600 Cost: 230.1727752685547\n",
      "(2:22) Epoch: 1700 Cost: 229.9633331298828\n",
      "(2:23) Epoch: 1800 Cost: 232.23190307617188\n",
      "(2:24) Epoch: 1900 Cost: 230.60316467285156\n",
      "(2:25) Epoch: 2000 Cost: 231.01666259765625\n",
      "(2:26) Epoch: 2100 Cost: 229.46556091308594\n",
      "(2:28) Epoch: 2200 Cost: 230.01904296875\n",
      "(2:29) Epoch: 2300 Cost: 229.73292541503906\n",
      "(2:30) Epoch: 2400 Cost: 230.32293701171875\n",
      "(2:31) Epoch: 2500 Cost: 230.29356384277344\n",
      "(2:33) Epoch: 2600 Cost: 229.78713989257812\n",
      "(2:34) Epoch: 2700 Cost: 230.17623901367188\n",
      "(2:35) Epoch: 2800 Cost: 230.86483764648438\n",
      "(2:37) Epoch: 2900 Cost: 229.8551025390625\n",
      "(2:39) Epoch: 3000 Cost: 229.75497436523438\n",
      "(2:40) Epoch: 3100 Cost: 228.91018676757812\n",
      "(2:42) Epoch: 3200 Cost: 230.13525390625\n",
      "(2:44) Epoch: 3300 Cost: 229.5704803466797\n",
      "(2:45) Epoch: 3400 Cost: 230.1044921875\n",
      "(2:47) Epoch: 3500 Cost: 222.12930297851562\n",
      "(2:49) Epoch: 3600 Cost: 227.1406707763672\n",
      "(2:51) Epoch: 3700 Cost: 216.72048950195312\n",
      "(2:53) Epoch: 3800 Cost: 218.67349243164062\n",
      "(2:55) Epoch: 3900 Cost: 207.00399780273438\n",
      "(2:57) Epoch: 4000 Cost: 219.1964111328125\n",
      "(2:59) Epoch: 4100 Cost: 202.06971740722656\n",
      "(3:2) Epoch: 4200 Cost: 210.9229278564453\n",
      "(3:4) Epoch: 4300 Cost: 205.23744201660156\n",
      "(3:6) Epoch: 4400 Cost: 190.91209411621094\n",
      "(3:9) Epoch: 4500 Cost: 213.91253662109375\n",
      "(3:11) Epoch: 4600 Cost: 208.89857482910156\n",
      "(3:14) Epoch: 4700 Cost: 218.6085662841797\n",
      "(3:16) Epoch: 4800 Cost: 207.64321899414062\n",
      "(3:19) Epoch: 4900 Cost: 202.62286376953125\n",
      "(3:22) Epoch: 5000 Cost: 204.14715576171875\n",
      "(3:24) Epoch: 5100 Cost: 213.2071075439453\n",
      "(3:27) Epoch: 5200 Cost: 205.89942932128906\n",
      "(3:30) Epoch: 5300 Cost: 199.18402099609375\n",
      "(3:33) Epoch: 5400 Cost: 204.1104736328125\n",
      "(3:36) Epoch: 5500 Cost: 223.20407104492188\n",
      "(3:39) Epoch: 5600 Cost: 204.06541442871094\n",
      "(3:42) Epoch: 5700 Cost: 216.28079223632812\n",
      "(3:45) Epoch: 5800 Cost: 212.05186462402344\n",
      "(3:49) Epoch: 5900 Cost: 214.13145446777344\n",
      "(3:52) Epoch: 6000 Cost: 211.18194580078125\n",
      "(3:56) Epoch: 6100 Cost: 215.8993682861328\n",
      "(3:59) Epoch: 6200 Cost: 216.83082580566406\n",
      "(4:3) Epoch: 6300 Cost: 208.0640869140625\n",
      "(4:6) Epoch: 6400 Cost: 216.57427978515625\n",
      "(4:10) Epoch: 6500 Cost: 198.21888732910156\n",
      "(4:14) Epoch: 6600 Cost: 217.60623168945312\n",
      "(4:17) Epoch: 6700 Cost: 198.5575714111328\n",
      "(4:21) Epoch: 6800 Cost: 208.2699737548828\n",
      "(4:25) Epoch: 6900 Cost: 213.6511993408203\n",
      "(4:29) Epoch: 7000 Cost: 206.7173309326172\n",
      "(4:33) Epoch: 7100 Cost: 207.96151733398438\n",
      "(4:37) Epoch: 7200 Cost: 209.42042541503906\n",
      "(4:42) Epoch: 7300 Cost: 212.34698486328125\n",
      "(4:46) Epoch: 7400 Cost: 217.17144775390625\n",
      "(4:50) Epoch: 7500 Cost: 206.0384521484375\n",
      "(4:55) Epoch: 7600 Cost: 207.96974182128906\n",
      "(4:59) Epoch: 7700 Cost: 201.55245971679688\n",
      "(5:4) Epoch: 7800 Cost: 199.2621307373047\n",
      "(5:8) Epoch: 7900 Cost: 218.49237060546875\n",
      "(5:13) Epoch: 8000 Cost: 226.2033233642578\n",
      "(5:18) Epoch: 8100 Cost: 207.62489318847656\n",
      "(5:23) Epoch: 8200 Cost: 186.0432586669922\n",
      "(5:28) Epoch: 8300 Cost: 208.08224487304688\n",
      "(5:33) Epoch: 8400 Cost: 210.0190887451172\n",
      "(5:38) Epoch: 8500 Cost: 216.56883239746094\n",
      "(5:43) Epoch: 8600 Cost: 190.8961181640625\n",
      "(5:48) Epoch: 8700 Cost: 203.5358123779297\n",
      "(5:54) Epoch: 8800 Cost: 200.5326690673828\n",
      "(5:59) Epoch: 8900 Cost: 211.16172790527344\n",
      "(6:5) Epoch: 9000 Cost: 210.30857849121094\n",
      "(6:10) Epoch: 9100 Cost: 211.500244140625\n",
      "(6:16) Epoch: 9200 Cost: 212.53955078125\n",
      "(6:22) Epoch: 9300 Cost: 200.15850830078125\n",
      "(6:27) Epoch: 9400 Cost: 203.9761962890625\n",
      "(6:33) Epoch: 9500 Cost: 216.12649536132812\n",
      "(6:39) Epoch: 9600 Cost: 205.87721252441406\n",
      "(6:45) Epoch: 9700 Cost: 212.95997619628906\n",
      "(6:52) Epoch: 9800 Cost: 205.24142456054688\n",
      "(6:58) Epoch: 9900 Cost: 210.48460388183594\n",
      "(7:4)Accuracy: 0.11129999905824661\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# neural network with 5 layers\n",
    "#\n",
    "# · · · · · · · · · ·          (input data, flattened pixels)       X [batch, 784]   \n",
    "# \\x/x\\x/x\\x/x\\x/x\\x/       -- fully connected layer (sigmoid)      W1 [784, 200]      B1[200]\n",
    "#  · · · · · · · · ·                                                Y1_hat [batch, 200]\n",
    "#   \\x/x\\x/x\\x/x\\x/         -- fully connected layer (sigmoid)      W2 [200, 100]      B2[100]\n",
    "#    · · · · · · ·                                                  Y2_hat [batch, 100]\n",
    "#     \\x/x\\x/x\\x/           -- fully connected layer (sigmoid)      W3 [100, 60]       B3[60]\n",
    "#      · · · · ·                                                    Y3_hat [batch, 60]\n",
    "#       \\x/x\\x/             -- fully connected layer (sigmoid)      W4 [60, 30]        B4[30]\n",
    "#        · · ·                                                      Y4_hat [batch, 30]\n",
    "#         \\x/               -- fully connected layer (softmax)      W5 [30, 10]        B5[10]\n",
    "#          ·                                                        Y_hat [batch, 10]\n",
    "\n",
    "# to reset the Tensorflow default graph\n",
    "reset_graph()\n",
    "\n",
    "########################################\n",
    "# define variables and placeholders\n",
    "########################################\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "Y = tf.placeholder(tf.int64, shape=(None))\n",
    "\n",
    "# variable learning rate\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "# probability of keeping a node during dropout = 1.0 at test time (no dropout) and 0.75 at training time\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "# five layers and their number of neurons, i.e., 200, 100, 60, 30, and 10\n",
    "# when using RELUs, make sure biases are initialised with small positive values, for example 0.1\n",
    "W1 = tf.get_variable(\"weights1\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([784, 200], minval=-0.5,\n",
    "    maxval=0.5))\n",
    "B1 = tf.get_variable(\"bias1\", dtype=tf.float32, initializer=tf.random_uniform([200], minval=0,\n",
    "    maxval=1))\n",
    "\n",
    "W2 = tf.get_variable(\"weights2\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([200, 100], minval=-0.5,\n",
    "    maxval=0.5))\n",
    "B2 = tf.get_variable(\"bias2\", dtype=tf.float32, initializer=tf.random_uniform([100], minval=0,\n",
    "    maxval=1))\n",
    "\n",
    "W3 = tf.get_variable(\"weights3\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([100, 60], minval=-0.5,\n",
    "    maxval=0.5))\n",
    "B3 = tf.get_variable(\"bias3\", dtype=tf.float32, initializer=tf.random_uniform([60], minval=0,\n",
    "    maxval=1))\n",
    "\n",
    "W4 = tf.get_variable(\"weights4\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([60, 30], minval=-0.5,\n",
    "    maxval=0.5))\n",
    "B4 = tf.get_variable(\"bias4\", dtype=tf.float32, initializer=tf.random_uniform([30], minval=0,\n",
    "    maxval=1))\n",
    "\n",
    "W5 = tf.get_variable(\"weights5\", dtype=tf.float32, \n",
    "                    initializer=tf.random_uniform([30, 10], minval=-0.5,\n",
    "    maxval=0.5))\n",
    "B5 = tf.get_variable(\"bias5\", dtype=tf.float32, initializer=tf.random_uniform([10], minval=0,\n",
    "    maxval=1))\n",
    "########################################\n",
    "# build the model\n",
    "########################################\n",
    "#XX = <FILL IN>\n",
    "\n",
    "Y1_hat = tf.nn.relu(tf.matmul(X, W1) + B1)\n",
    "Y1_hat_dropout = tf.nn.dropout(Y1_hat, 0.75)\n",
    "Y2_hat_dropout = tf.nn.dropout(tf.nn.relu(tf.matmul(Y1_hat_dropout, W2) + B2), 0.75)\n",
    "Y3_hat_dropout = tf.nn.dropout(tf.nn.relu(tf.matmul(Y2_hat_dropout, W3) + B3), 0.75)\n",
    "Y4_hat_dropout = tf.nn.dropout(tf.nn.relu(tf.matmul(Y3_hat_dropout, W4) + B4), 0.75)\n",
    "Y_hat = tf.nn.relu(tf.matmul(Y4_hat_dropout, W5) + B5)\n",
    "\n",
    "########################################\n",
    "# define the cost function\n",
    "########################################\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = Y_hat, labels = Y)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "########################################\n",
    "# define the optimizer\n",
    "########################################\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "########################################\n",
    "# execute the model\n",
    "########################################\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "max_learning_rate = 0.005\n",
    "min_learning_rate = 0.0001\n",
    "decay_speed = 2000.0\n",
    "\n",
    "batch_size = 100\n",
    "n_epochs = 10000\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs): \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        new_learning_rate = min_learning_rate + tf.math.multiply(tf.math.subtract(max_learning_rate, min_learning_rate), \n",
    "                                tf.math.exp(tf.math.xdivy(tf.math.negative(tf.to_float(epoch)), decay_speed))).eval()\n",
    "\n",
    "        if (epoch % 100 == 0):\n",
    "            print(\"({}:{}) Epoch: {} Cost: {}\".format(time.gmtime().tm_hour, time.gmtime().tm_min, epoch, cross_entropy.eval(session = sess, feed_dict = {X: batch_x, Y: batch_y, \n",
    "                                                        learning_rate: new_learning_rate})))\n",
    "        else: \n",
    "            sess.run(train_step, feed_dict = {X: batch_x, Y: batch_y, \n",
    "                                        learning_rate: new_learning_rate})\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(Y_hat, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    \n",
    "    print(\"({}:{})Accuracy: {}\".format(time.gmtime().tm_hour, time.gmtime().tm_min, sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels})))\n",
    "    \n",
    "    \n",
    "# 50% dropout, Accuracy: 0.10260000079870224\n",
    "# 75%: Accuracy: 0.1868000030517578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---\n",
    "# 6. Convolutional Network\n",
    "<img src=\"figs/16-comic6.png\" style=\"width: 500px;\"/>\n",
    "In the previous sections, all pixels of images flattened into a single vector, which was a really bad idea. Handwritten digits are made of shapes and we discarded the shape information when we flattened the pixels. However, we can use **convolutional neural networks (CNN)** to take advantage of shape information. CNNs apply *a series of filters* to the raw pixel data of an image to extract and learn higher-level features, which the model can then use for classification. CNNs contains three components:\n",
    "  - **Convolutional layers**: apply a specified number of convolution filters to the image. For each subregion, the layer performs a set of mathematical operations to produce a single value in the output feature map. Convolutional layers then typically apply a ReLU activation function to the output to introduce nonlinearities into the model.\n",
    "  - **Pooling layers**: downsample the image data extracted by the convolutional layers to reduce the dimensionality of the feature map in order to decrease processing time. A commonly used pooling algorithm is max pooling, which extracts subregions of the feature map (e.g., 2x2-pixel tiles), keeps their maximum value, and discards all other values.\n",
    "  - **Dense (fully connected) layers**: perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers. In a dense layer, every node in the layer is connected to every node in the preceding layer.\n",
    "  \n",
    "Typically, a CNN is composed of a *stack of **convolutional modules*** that perform feature extraction. Each *module* consists of a *convolutional layer* followed by a *pooling layer*. The last convolutional module is followed by one or more dense layers that perform classification. The final dense layer in a CNN contains a single neuron for each target class in the model, with a softmax activation function to generate a value between 0-1 for each neuron. We can interpret the softmax values for a given image as relative measurements of how likely it is that the image falls into each target class.\n",
    "\n",
    "Now, let us build a convolutional network for handwritten digit recognition. In this assignment, we will use the architecture shown in the following figure that has three convolutional layers, one fully-connected layer, and one softmax layer. Notice that the second and third convolutional layers have a stride of two that explains why they bring the number of output values down from 28x28 to 14x14 and then 7x7. A convolutional layer requires a weights tensor like `[4, 4, 3, 2]`, in which the first two numbers define the size of a filter (map), the third number shows the *depth* of the filter that is the number of *input channel*, and the last number shows the number of *output channel*. The output channel defines the number of times that we repeat the same thing with a different set of weights in one layer. In our implementation, we assume the output depth of first three convolutional layers, are 4, 8, 12, and the size of fully connected layer is 200.\n",
    "<img src=\"figs/17-arch1.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "Convolutional layers can be implemented in TensorFlow using the `tf.nn.conv2d` function, which performs the scanning of the input image in both directions using the supplied weights. This is only the weighted sum part of the neuron. You still need to add a bias and feed the result through an activation function. The padding strategy that works here is to copy pixels from the sides of the image. All digits are on a uniform background so this just extends the background and should not add any unwanted shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train accuracy: 0.12999999523162842, Loss: 414694048.0\n",
      "Epoch 100: Train accuracy: 0.699999988079071, Loss: 687688.0\n",
      "Epoch 200: Train accuracy: 0.6600000262260437, Loss: 1523296.0\n",
      "Epoch 300: Train accuracy: 0.800000011920929, Loss: 785600.0\n",
      "Epoch 400: Train accuracy: 0.7099999785423279, Loss: 889348.0625\n",
      "Epoch 500: Train accuracy: 0.6600000262260437, Loss: 885440.0625\n",
      "Epoch 600: Train accuracy: 0.6000000238418579, Loss: 793628.0\n",
      "Epoch 700: Train accuracy: 0.6399999856948853, Loss: 1055286.0\n",
      "Epoch 800: Train accuracy: 0.7599999904632568, Loss: 571164.0\n",
      "Epoch 900: Train accuracy: 0.7099999785423279, Loss: 491962.0\n",
      "Epoch 1000: Train accuracy: 0.6899999976158142, Loss: 498995.03125\n",
      "Epoch 1100: Train accuracy: 0.7900000214576721, Loss: 329938.0\n",
      "Epoch 1200: Train accuracy: 0.8600000143051147, Loss: 114807.9921875\n",
      "Epoch 1300: Train accuracy: 0.8600000143051147, Loss: 131242.0\n",
      "Epoch 1400: Train accuracy: 0.7699999809265137, Loss: 183813.0\n",
      "Epoch 1500: Train accuracy: 0.8899999856948853, Loss: 135720.0\n",
      "Epoch 1600: Train accuracy: 0.7699999809265137, Loss: 324744.0\n",
      "Epoch 1700: Train accuracy: 0.8600000143051147, Loss: 109324.0\n",
      "Epoch 1800: Train accuracy: 0.8199999928474426, Loss: 68738.0\n",
      "Epoch 1900: Train accuracy: 0.8299999833106995, Loss: 67338.0\n",
      "Epoch 2000: Train accuracy: 0.8100000023841858, Loss: 116538.0\n",
      "Epoch 2100: Train accuracy: 0.8399999737739563, Loss: 58061.0\n",
      "Epoch 2200: Train accuracy: 0.8600000143051147, Loss: 74671.0\n",
      "Epoch 2300: Train accuracy: 0.7699999809265137, Loss: 117459.0\n",
      "Epoch 2400: Train accuracy: 0.8600000143051147, Loss: 62121.00390625\n",
      "Epoch 2500: Train accuracy: 0.8299999833106995, Loss: 75625.0\n",
      "Epoch 2600: Train accuracy: 0.7400000095367432, Loss: 59901.75\n",
      "Epoch 2700: Train accuracy: 0.800000011920929, Loss: 46634.0\n",
      "Epoch 2800: Train accuracy: 0.8999999761581421, Loss: 10014.5\n",
      "Epoch 2900: Train accuracy: 0.8600000143051147, Loss: 37155.75\n",
      "Epoch 3000: Train accuracy: 0.7599999904632568, Loss: 50791.0\n",
      "Epoch 3100: Train accuracy: 0.800000011920929, Loss: 27700.75\n",
      "Epoch 3200: Train accuracy: 0.800000011920929, Loss: 23568.501953125\n",
      "Epoch 3300: Train accuracy: 0.8899999856948853, Loss: 14129.7880859375\n",
      "Epoch 3400: Train accuracy: 0.8600000143051147, Loss: 24364.75\n",
      "Epoch 3500: Train accuracy: 0.8899999856948853, Loss: 9831.03515625\n",
      "Epoch 3600: Train accuracy: 0.8799999952316284, Loss: 13976.625\n",
      "Epoch 3700: Train accuracy: 0.8999999761581421, Loss: 10280.53515625\n",
      "Epoch 3800: Train accuracy: 0.8799999952316284, Loss: 5526.625\n",
      "Epoch 3900: Train accuracy: 0.8899999856948853, Loss: 4496.12744140625\n",
      "Epoch 4000: Train accuracy: 0.7900000214576721, Loss: 13187.625\n",
      "Epoch 4100: Train accuracy: 0.8600000143051147, Loss: 5617.96533203125\n",
      "Epoch 4200: Train accuracy: 0.8600000143051147, Loss: 8845.8798828125\n",
      "Epoch 4300: Train accuracy: 0.8899999856948853, Loss: 3773.249755859375\n",
      "Epoch 4400: Train accuracy: 0.8500000238418579, Loss: 4208.3125\n",
      "Epoch 4500: Train accuracy: 0.8500000238418579, Loss: 5084.875\n",
      "Epoch 4600: Train accuracy: 0.8600000143051147, Loss: 8329.3251953125\n",
      "Epoch 4700: Train accuracy: 0.8999999761581421, Loss: 4708.63037109375\n",
      "Epoch 4800: Train accuracy: 0.8799999952316284, Loss: 3861.582275390625\n",
      "Epoch 4900: Train accuracy: 0.8799999952316284, Loss: 1866.0001220703125\n",
      "test data: accurecy = 0.8675000071525574, loss = 3105.768310546875\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "import time\n",
    "# · · · · · · · · · ·      (input data, 1-deep)               X [batch, 28, 28, 1]\n",
    "# @ @ @ @ @ @ @ @ @ @   -- conv. layer 5x5x1=>4 stride 1      W1 [5, 5, 1, 4]        B1 [4]\n",
    "# ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶                                         Y1_hat [batch, 28, 28, 4]\n",
    "#   @ @ @ @ @ @ @ @     -- conv. layer 5x5x4=>8 stride 2      W2 [5, 5, 4, 8]        B2 [8]\n",
    "#   ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶                                           Y2_hat [batch, 14, 14, 8]\n",
    "#     @ @ @ @ @ @       -- conv. layer 4x4x8=>12 stride 2     W3 [4, 4, 8, 12]       B3 [12]\n",
    "#     ∶∶∶∶∶∶∶∶∶∶∶                                             Y3_hat [batch, 7, 7, 12] => reshaped to YY [batch, 7*7*12]\n",
    "#      \\x/x\\x\\x/        -- fully connected layer (relu)       W4 [7*7*12, 200]       B4 [200]\n",
    "#       · · · ·                                               Y4_hat [batch, 200]\n",
    "#       \\x/x\\x/         -- fully connected layer (softmax)    W5 [200, 10]           B5 [10]\n",
    "#        · · ·                                                Y_hat [batch, 10]\n",
    "\n",
    "# to reset the Tensorflow default graph\n",
    "reset_graph()\n",
    "batch_size = 100\n",
    "\n",
    "########################################\n",
    "# define variables and placeholders\n",
    "########################################\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "# learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "# three convolutional layers with their channel counts, and a fully connected layer \n",
    "# (the last layer has 10 softmax neurons)\n",
    "# the output depth of first three convolutional layers, are 4, 8, 12, and the size of fully connected\n",
    "# layer is 200\n",
    "\n",
    "# shape=(filter_dim_x, filter_dim_y, input_layers, convolutions)\n",
    "W1 = tf.Variable(name = \"weights1\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([5,5,1,4], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B1 = tf.Variable(name = \"bias1\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [4]), trainable = True) # 1 per filter\n",
    "\n",
    "W2 = tf.Variable(name = \"weights2\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([5,5,4,8], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B2 = tf.Variable(name = \"bias2\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [8]), trainable = True) # 1 per filter\n",
    "\n",
    "W3 = tf.Variable(name = \"weights3\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([4,4,8,12], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B3 = tf.Variable(name = \"bias3\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [12]), trainable = True) # 1 per filter\n",
    "\n",
    "W4 = tf.Variable(name = \"weights4\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([7 * 7 * 12, 200], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B4 = tf.Variable(name = \"bias4\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [200]), trainable = True) # 1 per filter\n",
    "\n",
    "W5 = tf.Variable(name = \"weights5\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([200, 10], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B5 = tf.Variable(name = \"bias5\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [10]), trainable = True) # 1 per filter\n",
    "\n",
    "########################################\n",
    "# build the model\n",
    "########################################\n",
    "stride = 1  # output is 28x28\n",
    "Y1_hat = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding = 'SAME') + B1) # use tf.nn.conv2d\n",
    "\n",
    "stride = 2  # output is 14x14\n",
    "Y2_hat = tf.nn.relu(tf.nn.conv2d(Y1_hat, W2, strides=[1, stride, stride, 1], padding = 'SAME') + B2) # use tf.nn.conv2d\n",
    "\n",
    "stride = 2  # output is 7x7\n",
    "Y3_hat = tf.nn.relu(tf.nn.conv2d(Y2_hat, W3, strides=[1, stride, stride, 1], padding = 'SAME') + B3) # use tf.nn.conv2d\n",
    "\n",
    "# reshape the output from the third convolution for the fully connected layer\n",
    "YY_hat = tf.reshape(Y3_hat, [tf.shape(X)[0], 7 * 7 * 12])\n",
    "Y4_hat = tf.nn.relu(tf.matmul(YY_hat, W4) + B4)\n",
    "logits = tf.matmul(Y4_hat, W5) + B5\n",
    "y_hat = tf.nn.softmax(logits)\n",
    "\n",
    "########################################\n",
    "# define the cost function\n",
    "########################################\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_true)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "########################################\n",
    "# define the optmizer\n",
    "########################################\n",
    "lr = 0.003\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "train_step = optimizer.minimize(loss = cross_entropy, global_step=tf.train.get_global_step())\n",
    "\n",
    "########################################\n",
    "# execute the model\n",
    "########################################\n",
    "init = tf.global_variables_initializer()\n",
    "n_epochs = 5000\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    # print(tf.trainable_variables())\n",
    "    for iteration in range(n_epochs):\n",
    "        batch_X, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            a, c = sess.run([accuracy, cross_entropy], feed_dict={X: batch_X, y_true: batch_y})\n",
    "            print('Epoch {}: Train accuracy: {}, Loss: {}'.format(iteration, a, c))\n",
    "            out_weights = W5.eval()\n",
    "            # print(np.sum(out_weights))\n",
    "\n",
    "        # train\n",
    "        sess.run(train_step, feed_dict={X: batch_X, y_true: batch_y})\n",
    "        \n",
    "    a, c = sess.run([accuracy, cross_entropy], feed_dict={X: mnist.test.images, y_true: mnist.test.labels})\n",
    "    print('test data: accurecy = {}, loss = {}'.format(a, c))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Improve The Performance\n",
    "A good approach to sizing your neural networks is to implement a network that is a little too constrained, then give it a bit more degrees of freedom and add dropout to make sure it is not overfitting. This ends up with a fairly optimal network for your problem. In the above model, we set the output channel to 4 in the first convolutional layer, which means that we repeat the same filter shape (but with different weights) four times. If we assume that those filters evolve during training into shape recognisers, you can intuitively see that this might not be enough for our problem. Handwritten digits are made from more than 4 elemental shapes. So let us bump up the filter sizes a little, and also increase the number of filters in our convolutional layers from 4, 8, 12 to 6, 12, 24 and then add dropout on the fully-connected layer. The following figure shows the new architecture you should build. Please complete the following code based on the given architecture and dropout technique.\n",
    "<img src=\"figs/18-arch2.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train accuracy: 0.12999999523162842, Loss: 4116005888.0\n",
      "Epoch 100: Train accuracy: 0.1599999964237213, Loss: 3508354304.0\n",
      "Epoch 200: Train accuracy: 0.12999999523162842, Loss: 4094560512.0\n",
      "Epoch 300: Train accuracy: 0.11999999731779099, Loss: 4121275904.0\n",
      "Epoch 400: Train accuracy: 0.15000000596046448, Loss: 4640076800.0\n",
      "Epoch 500: Train accuracy: 0.14000000059604645, Loss: 4165452288.0\n",
      "Epoch 600: Train accuracy: 0.09000000357627869, Loss: 4301783040.0\n",
      "Epoch 700: Train accuracy: 0.12999999523162842, Loss: 4515278336.0\n",
      "Epoch 800: Train accuracy: 0.14000000059604645, Loss: 4358060032.0\n",
      "Epoch 900: Train accuracy: 0.07000000029802322, Loss: 4561107456.0\n",
      "Epoch 1000: Train accuracy: 0.14000000059604645, Loss: 4055534336.0\n",
      "Epoch 1100: Train accuracy: 0.1899999976158142, Loss: 3846390272.0\n",
      "Epoch 1200: Train accuracy: 0.11999999731779099, Loss: 3622874880.0\n",
      "Epoch 1300: Train accuracy: 0.1599999964237213, Loss: 3678336000.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-417e797fedd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mnew_learning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkeep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_learning_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {}: Train accuracy: {}, Loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Still not training properly... \n",
    "\n",
    "\n",
    "import time\n",
    "# · · · · · · · · · ·      (input data, 1-deep)               X [batch, 28, 28, 1]\n",
    "# @ @ @ @ @ @ @ @ @ @   -- conv. layer 5x5x1=>4 stride 1      W1 [5, 5, 1, 4]        B1 [4]\n",
    "# ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶                                         Y1_hat [batch, 28, 28, 4]\n",
    "#   @ @ @ @ @ @ @ @     -- conv. layer 5x5x4=>8 stride 2      W2 [5, 5, 4, 8]        B2 [8]\n",
    "#   ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶                                           Y2_hat [batch, 14, 14, 8]\n",
    "#     @ @ @ @ @ @       -- conv. layer 4x4x8=>12 stride 2     W3 [4, 4, 8, 12]       B3 [12]\n",
    "#     ∶∶∶∶∶∶∶∶∶∶∶                                             Y3_hat [batch, 7, 7, 12] => reshaped to YY [batch, 7*7*12]\n",
    "#      \\x/x\\x\\x/        -- fully connected layer (relu)       W4 [7*7*12, 200]       B4 [200]\n",
    "#       · · · ·                                               Y4_hat [batch, 200]\n",
    "#       \\x/x\\x/         -- fully connected layer (softmax)    W5 [200, 10]           B5 [10]\n",
    "#        · · ·                                                Y_hat [batch, 10]\n",
    "\n",
    "# to reset the Tensorflow default graph\n",
    "reset_graph()\n",
    "batch_size = 100\n",
    "\n",
    "########################################\n",
    "# define variables and placeholders\n",
    "########################################\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "# three convolutional layers with their channel counts, and a fully connected layer \n",
    "# (the last layer has 10 softmax neurons)\n",
    "# the output depth of first three convolutional layers, are 4, 8, 12, and the size of fully connected\n",
    "# layer is 200\n",
    "\n",
    "# shape=(filter_dim_x, filter_dim_y, input_layers, convolutions)\n",
    "W1 = tf.Variable(name = \"weights1\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([5,5,1,6], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B1 = tf.Variable(name = \"bias1\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [6]), trainable = True) # 1 per filter\n",
    "\n",
    "W2 = tf.Variable(name = \"weights2\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([5,5,6,12], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B2 = tf.Variable(name = \"bias2\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [12]), trainable = True) # 1 per filter\n",
    "\n",
    "W3 = tf.Variable(name = \"weights3\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([4,4,12,24], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B3 = tf.Variable(name = \"bias3\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [24]), trainable = True) # 1 per filter\n",
    "\n",
    "W4 = tf.Variable(name = \"weights4\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([7 * 7 * 24, 200], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B4 = tf.Variable(name = \"bias4\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [200]), trainable = True) # 1 per filter\n",
    "\n",
    "W5 = tf.Variable(name = \"weights5\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([200, 10], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B5 = tf.Variable(name = \"bias5\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [10]), trainable = True) # 1 per filter\n",
    "\n",
    "########################################\n",
    "# build the model\n",
    "########################################\n",
    "stride = 1  # output is 28x28\n",
    "Y1_hat = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding = 'SAME') + B1) # use tf.nn.conv2d\n",
    "\n",
    "stride = 2  # output is 14x14\n",
    "Y2_hat = tf.nn.relu(tf.nn.conv2d(Y1_hat, W2, strides=[1, stride, stride, 1], padding = 'SAME') + B2) # use tf.nn.conv2d\n",
    "\n",
    "stride = 2  # output is 7x7\n",
    "Y3_hat = tf.nn.relu(tf.nn.conv2d(Y2_hat, W3, strides=[1, stride, stride, 1], padding = 'SAME') + B3) # use tf.nn.conv2d\n",
    "\n",
    "# reshape the output from the third convolution for the fully connected layer\n",
    "YY_hat = tf.reshape(Y3_hat, [tf.shape(X)[0], 7 * 7 * 24])\n",
    "Y4_hat = tf.nn.relu(tf.matmul(YY_hat, W4) + B4)\n",
    "# YY4_hat = tf.nn.dropout(Y4_hat, pkeep) # kanske måste slanga på random seed? \n",
    "logits = tf.matmul(Y4_hat, W5) + B5\n",
    "y_hat = tf.nn.softmax(logits)\n",
    "\n",
    "########################################\n",
    "# define the cost function\n",
    "########################################\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_true)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "########################################\n",
    "# define the optmizer\n",
    "########################################\n",
    "lr = 0.005\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss = cross_entropy, global_step=tf.train.get_global_step())\n",
    "\n",
    "########################################\n",
    "# execute the model\n",
    "########################################\n",
    "init = tf.global_variables_initializer()\n",
    "n_epochs = 5000\n",
    "max_learning_rate = 0.005\n",
    "min_learning_rate = 0.0001\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    # print(tf.trainable_variables())\n",
    "    for iteration in range(n_epochs):\n",
    "        batch_X, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        new_learning_rate = min_learning_rate + tf.math.multiply(tf.math.subtract(max_learning_rate, min_learning_rate), \n",
    "        tf.math.exp(tf.math.xdivy(tf.math.negative(tf.to_float(epoch)), decay_speed))).eval()\n",
    "        new_learning_rate = 0.005\n",
    "        # train \n",
    "        a, c = sess.run([accuracy, cross_entropy], feed_dict={X: batch_X, y_true: batch_y, pkeep: 0.75, learning_rate: new_learning_rate})\n",
    "        if iteration % 100 == 0:\n",
    "            print('Epoch {}: Train accuracy: {}, Loss: {}'.format(iteration, a, c))\n",
    "\n",
    "        \n",
    "    a, c = sess.run([accuracy, cross_entropy], feed_dict={X: mnist.test.images, y_true: mnist.test.labels, pkeep: 1.0})\n",
    "    print('test data: accuracy = {}, loss = {}'.format(a, c))  \n",
    "# 10000 epocs lr 0.01 --> clearly overfitting\n",
    "# 5000 epocs lr 0.005 --> probably overfitting or stuck in local minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Tensorflow Layers Module\n",
    "The TensorFlow **layers** `tf.layers` module provides a high-level API that makes it easy to construct a neural network. It provides methods that facilitate: (i) the creation of dense (fully connected) layers and convolutional layers, (ii) adding activation functions, and (iii) applying dropout regularization. In this section use the module `tf.layers` to build the network you made in section 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: accurecy = 0.18000000715255737, loss = 229.36260986328125\n",
      "epoch 100: accurecy = 0.9300000071525574, loss = 17.235523223876953\n",
      "epoch 200: accurecy = 0.9700000286102295, loss = 14.939865112304688\n",
      "epoch 300: accurecy = 0.9599999785423279, loss = 14.98404312133789\n",
      "epoch 400: accurecy = 0.9599999785423279, loss = 11.164587020874023\n",
      "epoch 500: accurecy = 0.9700000286102295, loss = 9.224174499511719\n",
      "epoch 600: accurecy = 1.0, loss = 2.9929733276367188\n",
      "epoch 700: accurecy = 0.9800000190734863, loss = 11.214426040649414\n",
      "epoch 800: accurecy = 0.9800000190734863, loss = 3.565812110900879\n",
      "epoch 900: accurecy = 0.9599999785423279, loss = 30.281909942626953\n",
      "test data: accurecy = 0.9794999957084656, loss = 6.202642917633057\n"
     ]
    }
   ],
   "source": [
    "# · · · · · · · · · ·    (input data, 1-deep)                 X [batch, 28, 28, 1]\n",
    "# @ @ @ @ @ @ @ @ @ @ -- conv. layer 6x6x1=>6 stride 1        W1 [5, 5, 1, 6]        B1 [6]\n",
    "# ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶                                         Y1_hat [batch, 28, 28, 6]\n",
    "#   @ @ @ @ @ @ @ @   -- conv. layer 5x5x6=>12 stride 2       W2 [5, 5, 6, 12]        B2 [12]\n",
    "#   ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶                                           Y2_hat [batch, 14, 14, 12]\n",
    "#     @ @ @ @ @ @     -- conv. layer 4x4x12=>24 stride 2      W3 [4, 4, 12, 24]       B3 [24]\n",
    "#     ∶∶∶∶∶∶∶∶∶∶∶                                             Y3_hat [batch, 7, 7, 24] => reshaped to YY [batch, 7*7*24]\n",
    "#      \\x/x\\x\\x/ ✞    -- fully connected layer (relu+dropout) W4 [7*7*24, 200]       B4 [200]\n",
    "#       · · · ·                                               Y4_hat [batch, 200]\n",
    "#       \\x/x\\x/       -- fully connected layer (softmax)      W5 [200, 10]           B5 [10]\n",
    "#        · · ·                                                Y_hat [batch, 10]\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "#######################################\n",
    "# defineplaceholders\n",
    "########################################\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "########################################\n",
    "# build the model\n",
    "########################################\n",
    "# Convolutional Layer #1\n",
    "stride = 1\n",
    "conv1 = tf.layers.conv2d(inputs=X, filters=6, kernel_size=[6, 6], strides = [stride, stride], padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "# Convolutional Layer #2\n",
    "stride = 2\n",
    "conv2 = tf.layers.conv2d(inputs=conv1, filters=12, kernel_size=[5, 5], strides = [stride, stride], padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "# Convolutional Layer #3\n",
    "stride = 2\n",
    "conv3 = tf.layers.conv2d(inputs=conv2, \n",
    "                         filters=24, \n",
    "                         kernel_size=[4, 4], \n",
    "                         strides = [stride, stride], \n",
    "                         padding=\"SAME\", \n",
    "                         activation=tf.nn.relu)\n",
    "\n",
    "# reshape the output from the third convolution for the fully connected layer\n",
    "conv3_reshape = tf.reshape(conv3, [tf.shape(X)[0], 7 * 7 * 24])\n",
    "\n",
    "\n",
    "# Dense Layer\n",
    "# Input Tensor Shape: [batch_size, 200]\n",
    "# Output Tensor Shape: [batch_size, 200]\n",
    "dense = tf.layers.dense(inputs=conv3, units=200, activation=tf.nn.relu)\n",
    "\n",
    "# Add dropout operation\n",
    "dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=pkeep)\n",
    "\n",
    "# Logits layer\n",
    "# Input Tensor Shape: [batch_size, 200]\n",
    "# Output Tensor Shape: [batch_size, 10]\n",
    "logits = tf.layers.dense(inputs=conv3_reshape, units=10)\n",
    "y_hat = tf.nn.softmax(logits)\n",
    "\n",
    "########################################\n",
    "# define the cost and accuracy functions\n",
    "########################################\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_true)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "########################################\n",
    "# define the optimizer\n",
    "########################################\n",
    "lr = 0.003\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "########################################\n",
    "# execute the model\n",
    "########################################\n",
    "init = tf.global_variables_initializer()\n",
    "n_epochs = 1000\n",
    "batch_size = 100\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        # load batch of images and correct answers\n",
    "        batch_X, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # train\n",
    "        a, c = sess.run([accuracy, cross_entropy], feed_dict={X: batch_X, y_true: batch_y, pkeep: 0.75})\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            # a, c = sess.run([accuracy, cross_entropy], feed_dict={X: batch_X, y_true: batch_y, pkeep: 1.0})\n",
    "            print('epoch {}: accurecy = {}, loss = {}'.format(i, a, c))\n",
    "\n",
    "\n",
    "    a, c = sess.run([accuracy, cross_entropy], feed_dict={X: mnist.test.images, y_true: mnist.test.labels, pkeep: 1.0})\n",
    "    print('test data: accurecy = {}, loss = {}'.format(a, c))  \n",
    "##  without dropout, 1000 epochs: accurecy = 0.9836000204086304, loss = 5.435532569885254\n",
    "\n",
    "## with dropout: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 9. Keras\n",
    "Keras is a high-level API to build and train deep learning models. It's used for fast prototyping, advanced research, and production. `tf.keras` is TensorFlow's implementation of the Keras API specification. To work with Keras, you need to import `tf.keras` as part of your TensorFlow program setup.\n",
    "```\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "```\n",
    "#### Build a model\n",
    "In Keras, you assemble **layers** to build a model, i.e., a graph of layers. The most common type of model is a stack of layers: the `tf.keras.Sequential` model. For example, the following code builds a simple, fully-connected network (i.e., multi-layer perceptron):\n",
    "```\n",
    "model = tf.keras.Sequential()\n",
    "# adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# add another\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "```\n",
    "There are many `tf.keras.layers` available with some common constructor parameters:\n",
    "* `activation`: set the activation function for the layer, which is specified by the name of a built-in function or as a callable object.\n",
    "* `kernel_initializer` and `bias_initializer`: the initialization schemes that create the layer's weights (weight and bias).\n",
    "* `kernel_regularizer` and `bias_regularizer`: the regularization schemes that apply the layer's weights (weight and bias), such as L1 or L2 regularization.\n",
    "\n",
    "#### Train and evaluate\n",
    "After you construct a model, you can configure its learning process by calling the `compile` method:\n",
    "```\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "The method `tf.keras.Model.compile` takes three important arguments:\n",
    "* `optimizer`: it specifies the training procedure, e.g., `tf.train.AdamOptimizer` and `tf.train.GradientDescentOptimizer`.\n",
    "* `loss`: the cost function to minimize during optimization, e.g., mean square error (mse), categorical_crossentropy, and binary_crossentropy.\n",
    "* `metrics`: used to monitor training, e.g., `accuracy`.\n",
    "\n",
    "The next step after confiuring the model is to train it by calling the `model.fit` method and giving it training data as its input. After training the model you can call `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods to evaluate the inference-mode loss and metrics for the data provided or predict the output of the last layer in inference for the data provided, respectively.\n",
    "\n",
    "You can read more about Keras [here](https://www.tensorflow.org/guide/keras).\n",
    "\n",
    "\n",
    "In this task, please use Keras to rebuild the network you made in section 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Tensor dropout/keras_learning_phase:0, specified in either feed_devices or fetch_devices was not found in the Graph",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-46c8e88635de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test data: accurecy = {}, loss = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2981\u001b[0m         \u001b[0mfeed_symbols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_symbols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m         session != self._session):\n\u001b[0;32m-> 2983\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2926\u001b[0m       \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m     \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m     \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2929\u001b[0m     \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2930\u001b[0m     \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \"\"\"\n\u001b[1;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1425\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Tensor dropout/keras_learning_phase:0, specified in either feed_devices or fetch_devices was not found in the Graph"
     ]
    }
   ],
   "source": [
    "## Keras implementation\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# to reset the Tensorflow default graph\n",
    "reset_graph()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size=[6, 6], activation='relu', input_shape=[28, 28, 1], strides = 2))\n",
    "model.add(Conv2D(12, kernel_size=[5, 5], activation='relu', strides = 2))\n",
    "model.add(Conv2D(24, kernel_size=[4, 4], activation='relu', strides = 2))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "y_train = y_train.reshape(y_train.shape[0], 1, 1, 10)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1, 1, 10)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=100, \n",
    "          epochs=10, \n",
    "          verbose=1, \n",
    "          validation_data=(x_test, y_test))\n",
    "c, a = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test data: accurecy = {}, loss = {}'.format(a, c))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 10. Implement LeNet-5\n",
    "In this section, you should implement **LeNet-5** either using Tensorflow or Keras. Please take a look at its [paper](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) before starting to implement it.\n",
    "The LeNet-5 architecture is perhaps the most widely known CNN architecture. It was created by Yann LeCun in 1998 and widely used for handwritten digit recognition (MNIST). It is composed of the layers shown in the following table.\n",
    "<img src=\"figs/19-letnet5.png\" style=\"width: 600px;\"/>\n",
    "There are a few extra details to be noted:\n",
    "* MNIST images are 28×28 pixels, but they are zero-padded to 32×32 pixels and normalized before being fed to the network. The rest of the network does not use any padding, which is why the size keeps shrinking as the image progresses through the network.\n",
    "* The average pooling layers are slightly more complex than usual: each neuron computes the mean of its inputs, then multiplies the result by a learnable coefficient and adds a learnable bias term, then finally applies the activation function.\n",
    "* Most neurons in layer C3 maps are connected to neurons in only three or four S2 maps (instead of all six S2 maps). See table 1 in the [paper](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) for details.\n",
    "* The output layer is a bit special: instead of computing the dot product of the inputs and the weight vector, each neuron outputs the square of the Euclidian distance between its input vector and its weight vector. Each output measures how much the image belongs to a particular digit class. The cross-entropy cost function is now preferred, as it penalizes bad predictions much more, producing larger gradients and thus converging faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " 1200/60000 [..............................] - ETA: 1:31 - loss: 487.7701 - acc: 0.1925"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6fa2c528a016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test data: accurecy = {}, loss = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: Build the LetNet-5 model, and test it on MNIST\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, Activation, Flatten\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# to reset the Tensorflow default graph\n",
    "reset_graph()\n",
    "\n",
    "## Data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "x_train = np.pad(x_train, pad_width = ([0,0], [2,2], [2,2], [0,0]), mode = 'constant', constant_values = ([0,0], [0,0], [0,0], [0,0])).astype('float32')\n",
    "x_test = np.pad(x_test, pad_width = ([0,0], [2,2], [2,2], [0,0]), mode = 'constant', constant_values = ([0,0], [0,0], [0,0], [0,0])).astype('float32')\n",
    "\n",
    "# reshape to 4 dimensions \n",
    "y_train = y_train.reshape(y_train.shape[0], 1, 1, 10)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1, 1, 10)\n",
    "\n",
    "## Model \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size=[5, 5], activation='tanh', input_shape=[32, 32, 1], strides = 1)) # , data_format = 'channels_last'\n",
    "model.add(AveragePooling2D(2, strides=2))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Conv2D(16, kernel_size=[5, 5], activation='tanh', strides = 1))\n",
    "model.add(AveragePooling2D(pool_size=[2, 2], strides=2))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Conv2D(120, kernel_size=[5, 5], activation='tanh', strides = 1))\n",
    "model.add(Dense(84, activation='tanh'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer= SGD(0.01),# Adam(lr = 0.005, decay = 0.5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=100, \n",
    "          epochs=10, \n",
    "          verbose=1, \n",
    "          validation_data=(x_test, y_test))\n",
    "c, a = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test data: accurecy = {}, loss = {}'.format(a, c))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 11. Implement AlexNet\n",
    "In the last section, you should implement **AlexNet** either using Tensorflow or Keras. Again, please take a look at its [paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) before start to implement it.\n",
    "The AlexNet CNN architecture won the [ImageNet ILSVRC challenge](http://www.image-net.org/challenges/LSVRC/2012/) in 2012 by a large margin. It was developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. It is quite similar to LeNet-5, only much larger and deeper, and it was the first to stack convolutional layers directly on top of each other, instead of stacking a pooling layer on top of each convolutional layer. The following table presents this architecture.\n",
    "<img src=\"figs/20-alexnet.png\" style=\"width: 600px;\"/>\n",
    "To train the model, we need a big dataset, however, in this assignment you are going to to assign the pretrained weights to your model, using `tf.Variable.assign`. You can download the pretrained weights from [bvlc_alexnet.npy](https://www.cs.toronto.edu/~guerzhoy/tf_alexnet/bvlc_alexnet.npy). This file is a NumPy array file created by the python. After you read this file, you will receive a python dictionary with a <key, value> pair for each layer. Each key is one of the layers names, e.g., `conv1`, and each value is a list of two values: (1) weights, and (2) biases of that layer. Part of the function to load the weights and biases to your model is given, and you need to complete it.\n",
    "\n",
    "Here is what you see if you read and print the shape of each layer from the file:\n",
    "```\n",
    "weight_dic = np.load(\"bvlc_alexnet.npy\", encoding=\"bytes\").item()\n",
    "for layer in weights_dic:\n",
    "    print(\"-\" * 20)\n",
    "    print(layer)\n",
    "    for wb in weights_dic[layer]:\n",
    "        print(wb.shape)\n",
    "\n",
    "#--------------------\n",
    "# fc8\n",
    "# (4096, 1000) # weights\n",
    "# (1000,) # bias\n",
    "#--------------------\n",
    "# fc7\n",
    "# (4096, 4096) # weights\n",
    "# (4096,) # bias\n",
    "#--------------------\n",
    "# fc6\n",
    "# (9216, 4096) # weights\n",
    "# (4096,) # bias\n",
    "#--------------------\n",
    "# conv5\n",
    "# (3, 3, 192, 256) # weights\n",
    "# (256,) # bias\n",
    "#--------------------\n",
    "# conv4\n",
    "# (3, 3, 192, 384) # weights\n",
    "# (384,) # bias\n",
    "#--------------------\n",
    "# conv3\n",
    "# (3, 3, 256, 384) # weights\n",
    "# (384,) # bias\n",
    "#--------------------\n",
    "# conv2\n",
    "# (5, 5, 48, 256) # weights\n",
    "# (256,) # bias\n",
    "#--------------------\n",
    "# conv1\n",
    "# (11, 11, 3, 96) # weights\n",
    "# (96,) # bias\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxPoolLayer(x, kHeight, kWidth, strideX, strideY, name, padding = \"SAME\"):\n",
    "    return tf.nn.max_pool(x, ksize = [1, kHeight, kWidth, 1],\n",
    "                          strides = [1, strideX, strideY, 1], padding = padding, name = name)\n",
    " \n",
    "def dropout(x, keepPro, name = None):\n",
    "    return tf.nn.dropout(x, keepPro, name)\n",
    " \n",
    "def LRN(x, R, alpha, beta, name = None, bias = 1.0):\n",
    "    return tf.nn.local_response_normalization(x, depth_radius = R, alpha = alpha,\n",
    "                                              beta = beta, bias = bias, name = name)\n",
    " \n",
    "def fcLayer(x, inputD, outputD, reluFlag, name):\n",
    "    \"\"\"fully-connect\"\"\"\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        w = tf.get_variable(\"w\", shape = [inputD, outputD], dtype = \"float\")\n",
    "        b = tf.get_variable(\"b\", [outputD], dtype = \"float\")\n",
    "        out = tf.nn.xw_plus_b(x, w, b, name = scope.name)\n",
    "        if reluFlag:\n",
    "            return tf.nn.relu(out)\n",
    "        else:\n",
    "            return out\n",
    " \n",
    "def convLayer(x, kHeight, kWidth, strideX, strideY,\n",
    "              featureNum, name, padding = \"SAME\", groups = 1): #group=2 means the second part of AlexNet\n",
    "    \"\"\"convlutional\"\"\"\n",
    "    channel = int(x.get_shape()[-1]) #get channel\n",
    "    conv = lambda a, b: tf.nn.conv2d(a, b, strides = [1, strideY, strideX, 1], padding = padding)\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        w = tf.get_variable(\"w\", shape = [kHeight, kWidth, channel/groups, featureNum])\n",
    "        b = tf.get_variable(\"b\", shape = [featureNum])\n",
    " \n",
    "        xNew = tf.split(value = x, num_or_size_splits = groups, axis = 3)#input and weights after split\n",
    "        wNew = tf.split(value = w, num_or_size_splits = groups, axis = 3)\n",
    " \n",
    "        featureMap = [conv(t1, t2) for t1, t2 in zip(xNew, wNew)] #retriving the feature map separately\n",
    "        mergeFeatureMap = tf.concat(axis = 3, values = featureMap) #concatnating feature map \n",
    "        # print mergeFeatureMap.shape\n",
    "        out = tf.nn.bias_add(mergeFeatureMap, b)\n",
    "        return tf.nn.relu(tf.reshape(out, mergeFeatureMap.get_shape().as_list()), name = scope.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alexNet(object):\n",
    "    \"\"\"alexNet model\"\"\"\n",
    "    def __init__(self, x, keepPro, classNum, skip, modelPath = \"bvlc_alexnet.npy\"):\n",
    "        self.X = x\n",
    "        self.KEEPPRO = keepPro\n",
    "        self.CLASSNUM = classNum\n",
    "        self.SKIP = skip\n",
    "        self.MODELPATH = modelPath\n",
    "        #build CNN\n",
    "        self.buildCNN()\n",
    " \n",
    "    def buildCNN(self):\n",
    "        \"\"\"build model\"\"\"\n",
    "        conv1 = convLayer(self.X, 11, 11, 4, 4, 96, \"conv1\", \"VALID\")\n",
    "        lrn1 = LRN(conv1, 2, 2e-05, 0.75, \"norm1\")\n",
    "        pool1 = maxPoolLayer(lrn1, 3, 3, 2, 2, \"pool1\", \"VALID\")\n",
    " \n",
    "        conv2 = convLayer(pool1, 5, 5, 1, 1, 256, \"conv2\", groups = 2)\n",
    "        lrn2 = LRN(conv2, 2, 2e-05, 0.75, \"lrn2\")\n",
    "        pool2 = maxPoolLayer(lrn2, 3, 3, 2, 2, \"pool2\", \"VALID\")\n",
    " \n",
    "        conv3 = convLayer(pool2, 3, 3, 1, 1, 384, \"conv3\")\n",
    " \n",
    "        conv4 = convLayer(conv3, 3, 3, 1, 1, 384, \"conv4\", groups = 2)\n",
    " \n",
    "        conv5 = convLayer(conv4, 3, 3, 1, 1, 256, \"conv5\", groups = 2)\n",
    "        pool5 = maxPoolLayer(conv5, 3, 3, 2, 2, \"pool5\", \"VALID\")\n",
    " \n",
    "        fcIn = tf.reshape(pool5, [-1, 256 * 6 * 6])\n",
    "        fc1 = fcLayer(fcIn, 256 * 6 * 6, 4096, True, \"fc6\")\n",
    "        dropout1 = dropout(fc1, self.KEEPPRO)\n",
    " \n",
    "        fc2 = fcLayer(dropout1, 4096, 4096, True, \"fc7\")\n",
    "        dropout2 = dropout(fc2, self.KEEPPRO)\n",
    " \n",
    "        self.fc3 = fcLayer(dropout2, 4096, self.CLASSNUM, True, \"fc8\")\n",
    " \n",
    "    def loadModel(self, sess):\n",
    "        \"\"\"load model\"\"\"\n",
    "        wDict = np.load(self.MODELPATH, encoding = \"bytes\").item()\n",
    "        #for layers in model\n",
    "        for name in wDict:\n",
    "            if name not in self.SKIP:\n",
    "                with tf.variable_scope(name, reuse = True):\n",
    "                    for p in wDict[name]:\n",
    "                        if len(p.shape) == 1:\n",
    "                            #bias\n",
    "                            sess.run(tf.get_variable('b', trainable = False).assign(p))\n",
    "                        else:\n",
    "                            #weights\n",
    "                            sess.run(tf.get_variable('w', trainable = False).assign(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "import argparse\n",
    "import sys\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import caffe_classes\n",
    "import glob\n",
    "\n",
    "dropoutPro = 1\n",
    "classNum = 1000\n",
    "skip = []\n",
    "#get testImage\n",
    "testPath = \"test_images\"\n",
    "testImg = []\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    return glob.glob(os.path.join(path, '*')) # so there is no problem with hidden files\n",
    "\n",
    "for f in listdir_nohidden(testPath):\n",
    "    #print(f)\n",
    "    testImg.append(cv2.imread(f))\n",
    " \n",
    "imgMean = np.array([104, 117, 124], np.float)\n",
    "x = tf.placeholder(\"float\", [1, 227, 227, 3])\n",
    " \n",
    "model = alexNet(x, dropoutPro, classNum, skip)\n",
    "score = model.fc3\n",
    "softmax = tf.nn.softmax(score)\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    model.loadModel(sess) #Load the model\n",
    " \n",
    "    for i, img in enumerate(testImg):\n",
    "        #img preprocess\n",
    "        test = cv2.resize(img.astype(float), (227, 227)) #resize\n",
    "        test -= imgMean #subtract image mean\n",
    "        test = test.reshape((1, 227, 227, 3)) #reshape into tensor shape\n",
    "        maxx = np.argmax(sess.run(softmax, feed_dict = {x: test}))\n",
    "        res = caffe_classes.class_names[maxx] #find the max probility\n",
    "        #print(res)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, res, (int(img.shape[0]/3), int(img.shape[1]/3)), font, 1, (0, 0, 255), 2) #putting on the labels\n",
    "        cv2.imshow(\"demo\", img) \n",
    "        cv2.waitKey(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 3, 96)\n",
      "(96,)\n",
      "(5, 5, 48, 256)\n",
      "(256,)\n",
      "(3, 3, 256, 384)\n",
      "(384,)\n",
      "(3, 3, 192, 384)\n",
      "(384,)\n",
      "(3, 3, 192, 256)\n",
      "(256,)\n",
      "(9216, 4096)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(4096, 1000)\n",
      "(1000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (5, 5, 96, 256) and (5, 5, 48, 256) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c3805de703f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m#            #    session.run(weight.assign(wb))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mload_initial_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-c3805de703f5>\u001b[0m in \u001b[0;36mload_initial_weights\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m# loop over all layer names stored in the weights dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m#for layer_name in weights_dict:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mtuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m       \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_param\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2777\u001b[0m           assign_placeholder = array_ops.placeholder(tf_dtype,\n\u001b[1;32m   2778\u001b[0m                                                      shape=value.shape)\n\u001b[0;32m-> 2779\u001b[0;31m           \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2780\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2781\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m       \u001b[0mvalue_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[1;32m    953\u001b[0m           self.handle, value_tensor, name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    846\u001b[0m     \"\"\"\n\u001b[1;32m    847\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (5, 5, 96, 256) and (5, 5, 48, 256) are incompatible"
     ]
    }
   ],
   "source": [
    "## New version with Keras\n",
    "\n",
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# to reset the Tensorflow default graph\n",
    "reset_graph()\n",
    "\n",
    "# build the AlexNet model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(96, name = 'conv1', kernel_size=[11, 11], activation='relu', padding = 'same', input_shape=[224, 224, 3], strides = 4)) # , data_format = 'channels_last'\n",
    "model.add(MaxPooling2D(strides=3, padding = 'valid'))\n",
    "model.add(Conv2D(256, name = 'conv2', kernel_size=[5, 5], padding = 'same', activation='relu', strides = 1))\n",
    "model.add(MaxPooling2D(pool_size=[3, 3], strides=2, padding = 'valid'))\n",
    "model.add(Conv2D(384, name = 'conv3', kernel_size=[3, 3], padding = 'same', activation='relu', strides = 1))\n",
    "model.add(Conv2D(384, name = 'conv4', kernel_size=[3, 3], padding = 'same', activation='relu', strides = 1))\n",
    "model.add(Conv2D(256, name = 'conv5', kernel_size=[3, 3], padding = 'same', activation='relu', strides = 1))\n",
    "model.add(Dense(4096, name = 'fc6', activation='relu'))\n",
    "model.add(Dense(4096, name = 'fc7', activation='relu'))\n",
    "model.add(Dense(1000, name = 'fc8', activation='softmax'))\n",
    "\n",
    "# load inital weights and biases to the model\n",
    "def load_initial_weights(self, session):\n",
    "    # load the weights into memory\n",
    "    weights_dict = np.load('bvlc_alexnet.npy', encoding='bytes').item()\n",
    "    \n",
    "    all_weights = [weights_dict['conv1'][0], weights_dict['conv1'][1],\n",
    "    weights_dict['conv2'][0], weights_dict['conv2'][1],\n",
    "    weights_dict['conv3'][0], weights_dict['conv3'][1],\n",
    "    weights_dict['conv4'][0], weights_dict['conv4'][1],\n",
    "    weights_dict['conv5'][0], weights_dict['conv5'][1],\n",
    "    weights_dict['fc6'][0], weights_dict['fc6'][1],\n",
    "    weights_dict['fc7'][0], weights_dict['fc7'][1],\n",
    "    weights_dict['fc8'][0], weights_dict['fc8'][1]]\n",
    "    \n",
    "    for w in all_weights:\n",
    "        print(w.shape)\n",
    "        \n",
    "    \n",
    "    model.set_weights(all_weights)\n",
    "    # loop over all layer names stored in the weights dict\n",
    "    #for layer_name in weights_dict:\n",
    "    #    with tf.variable_scope(layer_name, reuse=True):\n",
    "    #        # loop over list of weights/biases and assign them to their corresponding tf variable\n",
    "    #        for wb in weights_dict[layer_name]:\n",
    "    #            \n",
    "    #            #layer_weights, layer_biases = wb[0], wb[1]\n",
    "    #            #layer = model.get_layer(layer_name)\n",
    "    #            #layer.set_weights([layer_weights, layer_biases])\n",
    "    #            #print(\"Done layer \", layer_name)\n",
    "    #            \n",
    "    #            ## biases\n",
    "    #            #if len(wb.shape) == 1:\n",
    "    #            #    bias = tf.get_variable(<FILL IN>)\n",
    "    #            #    session.run(bias.assign(wb))\n",
    "    #            ## weights\n",
    "    #            #else:\n",
    "    #            #    weight = tf.get_variable(<FILL IN>)\n",
    "    #            #    session.run(weight.assign(wb))\n",
    "##\n",
    "load_initial_weights(None, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-1ad31a8175e7>:134: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# to reset the Tensorflow default graph\n",
    "#reset_graph()\n",
    "\n",
    "# build the AlexNet model\n",
    "#<FILL IN> :)\n",
    "\n",
    "# load inital weights and biases to the model\n",
    "#def load_initial_weights(self, session):\n",
    "    # load the weights into memory\n",
    "#    weights_dic = np.load('bvlc_alexnet.npy', encoding='bytes').item()\n",
    "\n",
    "    # loop over all layer names stored in the weights dict\n",
    "#    for layer in weights_dict:\n",
    "#        with tf.variable_scope(layer, reuse=True):\n",
    "#            # loop over list of weights/biases and assign them to their corresponding tf variable\n",
    "#            for wb in weights_dict[layer]:\n",
    "#                # biases\n",
    "#                if len(wb.shape) == 1:\n",
    "#                    bias = tf.get_variable(<FILL IN>)\n",
    "#                    session.run(bias.assign(wb))\n",
    "#                # weights\n",
    "#                else:\n",
    "#                    weight = tf.get_variable(<FILL IN>)\n",
    "#                    session.run(weight.assign(wb))\n",
    " \n",
    "    \n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#\n",
    "# C1 \n",
    "#\n",
    "W1 = tf.Variable(name = \"w_conv1\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([11,11,3,96], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B1 = tf.Variable(name = \"b_conv1\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [96]), trainable = True) # 1 per filter\n",
    "\n",
    "C1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, 4, 4, 1], padding=\"SAME\") + B1)\n",
    "\n",
    "#\n",
    "# S2 \n",
    "#\n",
    "S2 = tf.nn.max_pool(C1, ksize = [1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "\n",
    "#\n",
    "# C3 \n",
    "#\n",
    "W3 = tf.Variable(name = \"w_conv2\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([5,5,96,256], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B3 = tf.Variable(name = \"b_conv2\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [256]), trainable = True) # 1 per filter\n",
    "\n",
    "C3 = tf.nn.relu(tf.nn.conv2d(S2, W3, strides=[1, 1, 1, 1], padding=\"SAME\") + B3)\n",
    "\n",
    "#\n",
    "# S4 \n",
    "#\n",
    "S4 = tf.nn.max_pool(C3, ksize = [1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "#\n",
    "# C5\n",
    "#\n",
    "W5 = tf.Variable(name = \"w_conv3\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([3,3,256,384], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B5 = tf.Variable(name = \"b_conv3\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [384]), trainable = True) # 1 per filter\n",
    "\n",
    "C5 = tf.nn.relu(tf.nn.conv2d(S4, W5, strides=[1, 1, 1, 1], padding=\"SAME\") + B5)\n",
    "\n",
    "#\n",
    "# C6\n",
    "#\n",
    "W6 = tf.Variable(name = \"w_conv4\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([3,3,384,384], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B6 = tf.Variable(name = \"b_conv4\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [384]), trainable = True) # 1 per filter\n",
    "\n",
    "C6 = tf.nn.relu(tf.nn.conv2d(C5, W6, strides=[1, 1, 1, 1], padding=\"SAME\") + B6)\n",
    "\n",
    "#\n",
    "# C7\n",
    "#\n",
    "W7 = tf.Variable(name = \"w_conv5\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([3,3,384,256], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B7 = tf.Variable(name = \"b_conv5\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [256]), trainable = True) # 1 per filter\n",
    "\n",
    "C7 = tf.nn.relu(tf.nn.conv2d(C6, W7, strides=[1, 1, 1, 1], padding=\"SAME\") + B7)\n",
    "\n",
    "\n",
    "\n",
    "# Flat C7 for dense layers\n",
    "C7_flat = tf.reshape(C7, [tf.shape(X)[0], 13 * 13 * 256])\n",
    "\n",
    "#\n",
    "# F8\n",
    "#\n",
    "W8 = tf.Variable(name = \"w_fc6\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([256 * 13 * 13, 4096], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B8 = tf.Variable(name = \"b_fc6\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [4096]), trainable = True) # 1 per filter\n",
    "\n",
    "F8 = tf.nn.relu(tf.matmul(C7_flat, W8) + B8)\n",
    "\n",
    "#\n",
    "# F9\n",
    "#\n",
    "W9 = tf.Variable(name = \"w_fc7\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([4096, 4096], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B9 = tf.Variable(name = \"b_fc7\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [4096]), trainable = True) # 1 per filter\n",
    "\n",
    "F9 = tf.nn.relu(tf.matmul(F8, W9) + B9)\n",
    "#\n",
    "# O10.- Output/Logits layer\n",
    "#\n",
    "W10 = tf.Variable(name = \"w_fc9\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([4096, 1000], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B10 = tf.Variable(name = \"b_fc9\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [1000]), trainable = True) # 1 per filter\n",
    "\n",
    "\n",
    "## STILL GETTING DIMENSION ERROR HERE \n",
    "O10 = tf.matmul(F9, W10) + B10\n",
    "\n",
    "y_hat = tf.nn.softmax(O10)\n",
    "\n",
    "# define the cost and accuracy functions\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=y_hat, labels=y_true)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# define the optimizer\n",
    "lr = 0.003\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "## load inital weights and biases to the model\n",
    "def load_initial_weights(session):\n",
    "#    # load the weights into memory\n",
    "    weights_dict = np.load('bvlc_alexnet.npy', encoding='bytes').item()\n",
    "    for name in weights_dict:\n",
    "        with tf.variable_scope(name, reuse = True):\n",
    "            for p in weights_dict[name]:\n",
    "                if len(p.shape) == 1:\n",
    "                    #bias\n",
    "                    sess.run(tf.get_variable('b', trainable = False).assign(p))\n",
    "                else:\n",
    "                    #weights\n",
    "                    sess.run(tf.get_variable('w', trainable = False).assign(p))\n",
    "    # loop over all layer names stored in the weights dict\n",
    "#    for layer in weights_dict:\n",
    " #       with tf.variable_scope(layer, reuse=True):\n",
    "  #          # loop over list of weights/biases and assign them to their corresponding tf variable\n",
    "   #         for wb in weights_dict[layer]:\n",
    "    #            # biases\n",
    "     #           if len(wb.shape) == 1:\n",
    "      #             print('b_' + layer)\n",
    "       #             #bias = tf.get_variable(layer, shape = wb.shape, trainable = False)\n",
    "       #             #session.run(bias.assign(wb))\n",
    "       #             session.run(tf.get_variable('b', trainable = False).assign(wb))\n",
    "       #             \n",
    "        #        # weights\n",
    "        #        else:\n",
    "         #           print('w_' + layer)\n",
    "          #          #weight = tf.get_variable(layer, shape = wb.shape, trainable = False)\n",
    "           #         #session.run(weight.assign(wb))\n",
    "            #        session.run(tf.get_variable('w', trainable = False).assign(wb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model\n",
    "After building the AlexNet model, you can test it on different images and present the accuracy of the model. To do so, first you need to use **OpenCV** library to make the images ready to give as input to the model. OpenCV is a library used for image processing. Below you can see how to read an image file and pre-process it using OpenCV to give it to the model. However, you need to complete the code and test the accuracy of your model. The teset images (shown below) are available in the `test_images` folder.\n",
    "<table width=\"100%\">\n",
    "<tr>\n",
    "<td><img src=\"test_images/test_image1.jpg\" style=\"width:200px;\"></td>\n",
    "<td><p align=\"center\"><img src=\"test_images/test_image2.jpg\" style=\"width:200px;\"></td>\n",
    "<td align=\"right\"><img src=\"test_images/test_image3.jpg\" style=\"width:200px;\"></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# test the AlexNet model on the given images\n",
    "\n",
    "import cv2\n",
    "\n",
    "#get list of all images\n",
    "current_dir = os.getcwd()\n",
    "image_path = os.path.join(current_dir, 'test_images')\n",
    "img_files = [os.path.join(image_path, f) for f in os.listdir(image_path) if f.endswith('.jpg')]\n",
    "\n",
    "#load all images\n",
    "imgs = []\n",
    "for f in img_files:\n",
    "    imgs.append(cv2.imread(f))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    <FILL IN>\n",
    "    \n",
    "    # loop over all images\n",
    "    for i, image in enumerate(imgs):\n",
    "        # convert image to float32 and resize to (227x227)\n",
    "        img = cv2.resize(image.astype(np.float32), (227, 227))\n",
    "        \n",
    "        # subtract the ImageNet mean\n",
    "        # Mean subtraction per channel was used to center the data around zero mean for each channel (R, G, B).\n",
    "        # This typically helps the network to learn faster since gradients act uniformly for each channel.\n",
    "        imagenet_mean = np.array([104., 117., 124.], dtype=np.float32)\n",
    "        img -= imagenet_mean\n",
    "        \n",
    "        # reshape as needed to feed into model\n",
    "        img = img.reshape((1, 227, 227, 3))\n",
    "        \n",
    "        <FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Old version from scratch \n",
    "\n",
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# to reset the Tensorflow default graph\n",
    "reset_graph()\n",
    "\n",
    "# build the AlexNet model\n",
    "\n",
    "# placeholders\n",
    "X = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#\n",
    "# C1 \n",
    "#\n",
    "W1 = tf.Variable(name = \"w_conv1\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([11,11,3,96], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B1 = tf.Variable(name = \"b_conv1\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [96]), trainable = True) # 1 per filter\n",
    "\n",
    "C1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, 4, 4, 1], padding=\"SAME\") + B1)\n",
    "\n",
    "#\n",
    "# S2 \n",
    "#\n",
    "S2 = tf.nn.max_pool(C1, ksize = [1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "\n",
    "#\n",
    "# C3 \n",
    "#\n",
    "W3 = tf.Variable(name = \"w_conv2\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([5,5,96,256], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B3 = tf.Variable(name = \"b_conv2\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [256]), trainable = True) # 1 per filter\n",
    "\n",
    "C3 = tf.nn.relu(tf.nn.conv2d(S2, W3, strides=[1, 1, 1, 1], padding=\"SAME\") + B3)\n",
    "\n",
    "#\n",
    "# S4 \n",
    "#\n",
    "S4 = tf.nn.max_pool(C3, ksize = [1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "#\n",
    "# C5\n",
    "#\n",
    "W5 = tf.Variable(name = \"w_conv3\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([3,3,256,384], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B5 = tf.Variable(name = \"b_conv3\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [384]), trainable = True) # 1 per filter\n",
    "\n",
    "C5 = tf.nn.relu(tf.nn.conv2d(S4, W5, strides=[1, 1, 1, 1], padding=\"SAME\") + B5)\n",
    "\n",
    "#\n",
    "# C6\n",
    "#\n",
    "W6 = tf.Variable(name = \"w_conv4\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([3,3,384,384], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B6 = tf.Variable(name = \"b_conv4\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [384]), trainable = True) # 1 per filter\n",
    "\n",
    "C6 = tf.nn.relu(tf.nn.conv2d(C5, W6, strides=[1, 1, 1, 1], padding=\"SAME\") + B6)\n",
    "\n",
    "#\n",
    "# C7\n",
    "#\n",
    "W7 = tf.Variable(name = \"w_conv5\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([3,3,384,256], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B7 = tf.Variable(name = \"b_conv5\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [256]), trainable = True) # 1 per filter\n",
    "\n",
    "C7 = tf.nn.relu(tf.nn.conv2d(C6, W7, strides=[1, 1, 1, 1], padding=\"SAME\") + B7)\n",
    "\n",
    "\n",
    "\n",
    "# Flat C7 for dense layers\n",
    "C7_flat = tf.reshape(C7, [tf.shape(X)[0], 13 * 13 * 256])\n",
    "\n",
    "#\n",
    "# F8\n",
    "#\n",
    "W8 = tf.Variable(name = \"w_fc6\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([256 * 13 * 13, 4096], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B8 = tf.Variable(name = \"b_fc6\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [4096]), trainable = True) # 1 per filter\n",
    "\n",
    "F8 = tf.nn.relu(tf.matmul(C7_flat, W8) + B8)\n",
    "\n",
    "#\n",
    "# F9\n",
    "#\n",
    "W9 = tf.Variable(name = \"w_fc7\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([4096, 4096], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B9 = tf.Variable(name = \"b_fc7\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [4096]), trainable = True) # 1 per filter\n",
    "\n",
    "F9 = tf.nn.relu(tf.matmul(F8, W9) + B9)\n",
    "#\n",
    "# O10.- Output/Logits layer\n",
    "#\n",
    "W10 = tf.Variable(name = \"w_fc9\", dtype=tf.float32, \n",
    "                    initial_value=tf.random_uniform([4096, 1000], minval=0, maxval=1), trainable = True)\n",
    "\n",
    "B10 = tf.Variable(name = \"b_fc9\", dtype=tf.float32, initial_value=tf.constant(0.1, tf.float32, [1000]), trainable = True) # 1 per filter\n",
    "\n",
    "\n",
    "## STILL GETTING DIMENSION ERROR HERE \n",
    "O10 = tf.matmul(F9, W10) + B10\n",
    "\n",
    "y_hat = tf.nn.softmax(O10)\n",
    "\n",
    "# define the cost and accuracy functions\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=y_hat, labels=y_true)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# define the optimizer\n",
    "lr = 0.003\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "## load inital weights and biases to the model\n",
    "def load_initial_weights(session):\n",
    "#    # load the weights into memory\n",
    "    weights_dict = np.load('bvlc_alexnet.npy', encoding='bytes').item()\n",
    "    for name in weights_dict:\n",
    "        with tf.variable_scope(name, reuse = True):\n",
    "            for p in weights_dict[name]:\n",
    "                if len(p.shape) == 1:\n",
    "                    #bias\n",
    "                    sess.run(tf.get_variable('b', trainable = False).assign(p))\n",
    "                else:\n",
    "                    #weights\n",
    "                    sess.run(tf.get_variable('w', trainable = False).assign(p))\n",
    "    # loop over all layer names stored in the weights dict\n",
    "#    for layer in weights_dict:\n",
    " #       with tf.variable_scope(layer, reuse=True):\n",
    "  #          # loop over list of weights/biases and assign them to their corresponding tf variable\n",
    "   #         for wb in weights_dict[layer]:\n",
    "    #            # biases\n",
    "     #           if len(wb.shape) == 1:\n",
    "      #             print('b_' + layer)\n",
    "       #             #bias = tf.get_variable(layer, shape = wb.shape, trainable = False)\n",
    "       #             #session.run(bias.assign(wb))\n",
    "       #             session.run(tf.get_variable('b', trainable = False).assign(wb))\n",
    "       #             \n",
    "        #        # weights\n",
    "        #        else:\n",
    "         #           print('w_' + layer)\n",
    "          #          #weight = tf.get_variable(layer, shape = wb.shape, trainable = False)\n",
    "           #         #session.run(weight.assign(wb))\n",
    "            #        session.run(tf.get_variable('w', trainable = False).assign(wb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model\n",
    "After building the AlexNet model, you can test it on different images and present the accuracy of the model. To do so, first you need to use **OpenCV** library to make the images ready to give as input to the model. OpenCV is a library used for image processing. Below you can see how to read an image file and pre-process it using OpenCV to give it to the model. However, you need to complete the code and test the accuracy of your model. The teset images (shown below) are available in the `test_images` folder.\n",
    "<table width=\"100%\">\n",
    "<tr>\n",
    "<td><img src=\"test_images/test_image1.jpg\" style=\"width:200px;\"></td>\n",
    "<td><p align=\"center\"><img src=\"test_images/test_image2.jpg\" style=\"width:200px;\"></td>\n",
    "<td align=\"right\"><img src=\"test_images/test_image3.jpg\" style=\"width:200px;\"></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable fc6/w does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-63cdd949909f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mload_initial_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# loop over all images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-1ad31a8175e7>\u001b[0m in \u001b[0;36mload_initial_weights\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0;31m#weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;31m# loop over all layer names stored in the weights dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m#    for layer in weights_dict:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1485\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1235\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    538\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    490\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    877\u001b[0m       raise ValueError(\"Variable %s does not exist, or was not created with \"\n\u001b[1;32m    878\u001b[0m                        \u001b[0;34m\"tf.get_variable(). Did you mean to set \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                        \"reuse=tf.AUTO_REUSE in VarScope?\" % name)\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;31m# Create the tensor to initialize the variable with default value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable fc6/w does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# test the AlexNet model on the given images\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "#get list of all images\n",
    "current_dir = os.getcwd()\n",
    "image_path = os.path.join(current_dir, 'test_images')\n",
    "img_files = [os.path.join(image_path, f) for f in os.listdir(image_path) if f.endswith('.jpg')]\n",
    "\n",
    "#load all images\n",
    "imgs = []\n",
    "for f in img_files:\n",
    "    imgs.append(cv2.imread(f))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    load_initial_weights(sess)\n",
    "    \n",
    "    # loop over all images\n",
    "    for i, image in enumerate(imgs):\n",
    "        # convert image to float32 and resize to (227x227)\n",
    "        img = cv2.resize(image.astype(np.float32), (227, 227))\n",
    "        \n",
    "        # subtract the ImageNet mean\n",
    "        # Mean subtraction per channel was used to center the data around zero mean for each channel (R, G, B).\n",
    "        # This typically helps the network to learn faster since gradients act uniformly for each channel.\n",
    "        imagenet_mean = np.array([104., 117., 124.], dtype=np.float32)\n",
    "        img -= imagenet_mean\n",
    "        \n",
    "        # reshape as needed to feed into model\n",
    "        img = img.reshape((1, 227, 227, 3))\n",
    "        \n",
    "        maxx = np.argmax(sess.run(softmax, feed_dict = {x: test}))\n",
    "        res = caffe_classes.class_names[maxx] #find the max probility\n",
    "        #print(res)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, res, (int(img.shape[0]/3), int(img.shape[1]/3)), font, 1, (0, 0, 255), 2) #putting on the labels\n",
    "        cv2.imshow(\"demo\", img) \n",
    "        cv2.waitKey(5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
